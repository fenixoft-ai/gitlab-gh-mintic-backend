{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué hace este script?\n",
    "\n",
    "Calcula para cada dispositivo de red(AP) y rango de fecha, el tiempo promedio de sesión (usuarios.tiempoPromedioSesionSitio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from ssl import create_default_context\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import parametros\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectando a ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ultima línea se utiliza para garantizar la ejecución de la consulta\n",
    "* timeout es el tiempo para cada ejecución\n",
    "* max_retries el número de intentos si la conexión falla\n",
    "* retry_on_timeout para activar los reitentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = create_default_context(cafile=parametros.cafile)\n",
    "es = Elasticsearch(\n",
    "    parametros.servidor,\n",
    "    http_auth=(parametros.usuario_EC, parametros.password_EC),\n",
    "    scheme=\"https\",\n",
    "    port=parametros.puerto,\n",
    "    ssl_context=context,\n",
    "    timeout=60, max_retries=3, retry_on_timeout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando fechas para la ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se calculan las fechas para asociar al nombre del indice\n",
    "* fecha_hoy es usada para concatenar al nombre del indice principal previa inserción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "fecha_hoy = str(now.strftime(\"%Y.%m.%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nombre de indice donde se insertará e indice para control de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = parametros.usuarios_tablero07_index\n",
    "indice_control = parametros.tableros_mintic_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para JSON compatible con ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterKeys(document):\n",
    "    return {key: document[key] for key in use_these_keys }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trae la ultima fecha para control de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando en el rango de tiempo de la ejecución, no se insertan nuevos valores, las fecha maxima en indice mintic no aumenta, por tanto se usa esta fecha de control para garantizar que incremente el bucle de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 1\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= indice_control,\n",
    "        body={\n",
    "               \"_source\": [\"usuarios.Tablero07.fechaControl\"],\n",
    "              \"query\": {\n",
    "                \"bool\": {\n",
    "                  \"filter\": [\n",
    "                  {\n",
    "                    \"exists\": {\n",
    "                      \"field\":\"jerarquia-tablero07\"\n",
    "                    }\n",
    "                  }\n",
    "                  ]\n",
    "                }\n",
    "              }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        #print(doc[\"_source\"])\n",
    "        fecha_ejecucion = doc[\"_source\"]['usuarios.Tablero07.fechaControl']\n",
    "except Exception as e:\n",
    "    print(\"Error:\")\n",
    "    print(e)\n",
    "    fecha_ejecucion = '2021-05-01 00:00:00'\n",
    "    pass\n",
    "if response[\"hits\"][\"hits\"] == []:\n",
    "    fecha_ejecucion = '2021-05-01 00:00:00'\n",
    "print(\"ultima fecha para control de ejecucion:\",fecha_ejecucion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leyendo indice semilla-inventario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el script que ingesta semilla, trae la información de los centros de conexión administrados. Para el indice principal se requiere:\n",
    "* site_id como llave del centro de conexión.\n",
    "* Datos geográficos (Departamento, municipio, centro poblado, sede, energía, latitud, longitud, COD_ISO, id_Beneficiario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 10000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= parametros.semilla_inventario_index,\n",
    "        body={\n",
    "               \"_source\": ['site_id','nombre_municipio', 'nombre_departamento', 'nombre_centro_pob', 'nombreSede' \n",
    "                           , 'energiadesc', 'latitud', 'longitud', 'COD_ISO','id_Beneficiario']\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "#     fields = {}\n",
    "#     for num, doc in enumerate(elastic_docs):\n",
    "#         source_data = doc[\"_source\"]\n",
    "#         for key, val in source_data.items():\n",
    "#             try:\n",
    "#                 fields[key] = np.append(fields[key], val)\n",
    "#             except KeyError:\n",
    "#                 fields[key] = np.array([val])\n",
    "\n",
    "#     datos_semilla = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\n",
    "    datos_semilla = pd.DataFrame([x[\"_source\"] for x in elastic_docs])\n",
    "except:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiando nombre de campos y generando location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se valida latitud y longitud. Luego se calcula campo location\n",
    "* Se renombran los campos de semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(x):\n",
    "    patron = re.compile('^(\\-?\\d+(\\.\\d+)?),\\s*(\\-?\\d+(\\.\\d+)?)$') #patrón que debe cumplir\n",
    "    if (not patron.match(x) is None):\n",
    "        return x.replace(',','.')\n",
    "    else:\n",
    "        #Código a ejecutar si las coordenadas no son válidas\n",
    "        return 'a'\n",
    "datos_semilla['latitud'] = datos_semilla['latitud'].apply(get_location)\n",
    "datos_semilla['longitud'] = datos_semilla['longitud'].apply(get_location)\n",
    "datos_semilla = datos_semilla.drop(datos_semilla[(datos_semilla[\"longitud\"]=='a') | (datos_semilla[\"latitud\"]=='a')].index)\n",
    "datos_semilla['usuarios.location'] = datos_semilla['latitud'] + ',' + datos_semilla['longitud']\n",
    "datos_semilla['usuarios.location']=datos_semilla['usuarios.location'].str.replace('a,a','')\n",
    "datos_semilla.drop(columns=['latitud','longitud'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_semilla = datos_semilla.rename(columns={'lugar_cod' : 'usuarios.centroDigitalUsuarios'\n",
    "                                            , 'nombre_municipio': 'usuarios.nombreMunicipio'\n",
    "                                            , 'nombre_departamento' : 'usuarios.nombreDepartamento'\n",
    "                                            , 'nombre_centro_pob': 'usuarios.localidad'\n",
    "                                            , 'nombreSede' : 'usuarios.nomCentroDigital'\n",
    "                                            , 'energiadesc' : 'usuarios.sistemaEnergia'\n",
    "                                            , 'COD_ISO' : 'usuarios.codISO'\n",
    "                                            , 'id_Beneficiario' : 'usuarios.idBeneficiario'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se descartan los registros que tengan la latitud y longitud vacía o no valida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datos_semilla = datos_semilla.drop(datos_semilla[(datos_semilla[\"usuarios.location\"]=='')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos_semilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leyendo indice cambium-devicedevices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta formas se asocia las MAC de dispositivos de red INDOOR y OUTDOOR\n",
    "* site_id para cruzar con las misma llave de semilla.\n",
    "* datos del dispositivo: mac, status, ip.\n",
    "* ap_group para identificar si la conexión es indoor/outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 30000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= parametros.cambium_d_d_index,\n",
    "        body={\n",
    "                    \"_source\": [\"site_id\",\"mac\",\"status\",\"ip\",\"ap_group\"]\n",
    "                  , \"query\": {\n",
    "                    \"match_all\": {}\n",
    "                  }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "\n",
    "    datos_dev = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\n",
    "except:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev.dropna(subset=['site_id'], inplace=True)\n",
    "datos_dev.fillna('', inplace=True)\n",
    "datos_dev = datos_dev.drop(datos_dev[(datos_dev['site_id']=='')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se corrigen datos de ap group con formato no valido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev['ap_group'] = datos_dev['ap_group'].str.split(\"-\", n = 1, expand = True)[0]\n",
    "datos_dev['ap_group'] = datos_dev['ap_group'].str.split(\"_\", n = 1, expand = True)[0]\n",
    "datos_dev['ap_group'] = datos_dev['ap_group'].str.split(\".\", n = 1, expand = True)[0]\n",
    "datos_dev = datos_dev.drop(datos_dev[(datos_dev['ap_group']=='')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toman solo los datos con site_id y mac unicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev = datos_dev.drop_duplicates('mac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambia el nombre a la mac del dispositivo de red para no confundir con la de dispositivos de usuario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev= datos_dev.rename(columns={'mac' : 'usuarios.macRed','ap_group' : 'usuarios.apGroup'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se lee información de Ohmyfi consumos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartir de esta lectura se toma el valor del tiempo promedio de sesión en minutos. Se toma de referencia los campos:\n",
    "* fecha_inicio a partir de la cual se calcula fecha control\n",
    "* tiempo_sesion_minutos\n",
    "* mac_usuario \n",
    "* lugar_cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traeSesiones(fecha_max,fecha_tope):\n",
    "    total_docs = 500000\n",
    "    response = es.search(\n",
    "        index= parametros.ohmyfi_consumos_index,\n",
    "        body={\n",
    "                  \"_source\": [\"lugar_cod\", \"tiempo_sesion_minutos\",\"mac_ap\",\"fecha_inicio\"]\n",
    "                 ,\"query\": {\n",
    "                      \"range\": {\n",
    "                            \"fecha_inicio\": {\n",
    "                            \"gte\": fecha_max,\n",
    "                            \"lt\": fecha_tope\n",
    "                            }\n",
    "                        }\n",
    "                  }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "#     fields = {}\n",
    "#     for num, doc in enumerate(elastic_docs):\n",
    "#         source_data = doc[\"_source\"]\n",
    "#         for key, val in source_data.items():\n",
    "#             try:\n",
    "#                 fields[key] = np.append(fields[key], val)\n",
    "#             except KeyError:\n",
    "#                 fields[key] = np.array([val])\n",
    "\n",
    "#     return pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) \n",
    "    return pd.DataFrame([x[\"_source\"] for x in elastic_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trae_conexiones(fecha_ini,fecha_fin):\n",
    "    total_docs = 5000000\n",
    "    response = es.search(\n",
    "        index= parametros.ohmyfi_d_c_index,\n",
    "        body={\n",
    "                \"_source\": [\"fechahora\",\"fecha_control\",\"lugar\",\"lugar_cod\",\"mac_usuario\", \"dispositivo\"\n",
    "                            ,\"sistema_operativo\",'tipodoc','documento']\n",
    "                , \"query\": {\n",
    "                  \"range\": {\n",
    "                    \"fechahora\": {\n",
    "                      \"gte\": fecha_ini,\n",
    "                      \"lt\": fecha_fin\n",
    "                    }\n",
    "                  }\n",
    "              }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "\n",
    "    return pd.DataFrame([x[\"_source\"] for x in elastic_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se ejecuta consulta de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se calcula rango en base a la fecha de control. Para este caso es de 10 minutos.\n",
    "* Se ejecuta la función de consulta con el rango de fechas.\n",
    "* Si no retorna datos se incrementa el rango y se ejecuta nuevamente. Este proceso se repite hasta conseguir datos o hasta que el rango de ejecución alcance la fecha y hora actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_max_mintic = fecha_ejecucion\n",
    "\n",
    "fecha_tope_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=50)-timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "datos_consumos = traeSesiones(fecha_max_mintic,fecha_tope_mintic)\n",
    "\n",
    "if datos_consumos is None or datos_consumos.empty:\n",
    "    while (datos_consumos is None or datos_consumos.empty) and ((datetime.strptime(fecha_max_mintic[0:50], '%Y-%m-%d %H:%M:%S').strftime(\"%Y-%m-%d %H:%M:%S\")) < str(now.strftime(\"%Y-%m-%d %H:%M:%S\"))):\n",
    "        fecha_max_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=50)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_tope_mintic = (datetime.strptime(fecha_tope_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=50)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        datos_consumos = traeSesiones(fecha_max_mintic,fecha_tope_mintic)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_det_conex = trae_conexiones(fecha_max_mintic,fecha_tope_mintic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuar = True\n",
    "if datos_det_conex.empty:\n",
    "    print(\"Dataframe vacio\")\n",
    "    print(fecha_max_mintic)\n",
    "    print(fecha_tope_mintic)\n",
    "    \n",
    "    continuar = False\n",
    "else:\n",
    "    datos_det_conex['fecha'] = datos_det_conex['fecha_control'].str.split(\" \", n = 1, expand = True)[0]\n",
    "    datos_det_conex.drop_duplicates(subset=[\"fecha_control\",\"lugar\",\"lugar_cod\",\"mac_usuario\", \"dispositivo\",\"sistema_operativo\",'tipodoc','documento'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #datos_det_conex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  continuar:\n",
    "    \n",
    "    datos_det_conex = datos_det_conex.rename(columns={'lugar_cod' : 'site_id'\n",
    "                                                             ,'fechahora':'usuarios.fechaConexionUsuarios'\n",
    "                                                             ,'dispositivo': 'usuarios.tipoDispositivoUsuarios'\n",
    "                                                             , 'sistema_operativo': 'usuarios.sistemaOperativoUsuarios'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datos_det_conex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos_det_conex.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se lee el indice all-cambium-device-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En este indice se guarda el detalle de los radio por fecha\n",
    "* Detalle conexiones cruza con device clients. Con estos se calculan los totales por marca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traeRadio(fecha_max,fecha_tope):\n",
    "    total_docs = 100000\n",
    "    response = es.search(\n",
    "        index= 'all-'+parametros.cambium_d_c_index,\n",
    "        body={\n",
    "            \"_source\": ['mac', 'ap_mac', 'radio.band', 'radio.rx_bytes', 'radio.tx_bytes','fecha_control']\n",
    "              , \"query\": {\n",
    "                  \"range\": {\n",
    "                    \"fecha_control\": {\n",
    "                      \"gte\": fecha_max_mintic,\n",
    "                      \"lt\": fecha_tope_mintic\n",
    "                      #\"gte\": \"2021-05-26 15:00:00\",\n",
    "                      #\"lt\": \"2021-05-26 15:10:00\"  \n",
    "                    }\n",
    "                  }\n",
    "              }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    # fields = {}\n",
    "    # for num, doc in enumerate(elastic_docs):\n",
    "    #     source_data = doc[\"_source\"]\n",
    "    #     for key, val in source_data.items():\n",
    "    #         try:\n",
    "    #             fields[key] = np.append(fields[key], val)\n",
    "    #         except KeyError:\n",
    "    #             fields[key] = np.array([val])\n",
    "\n",
    "    # datos_radio = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ]))\n",
    "\n",
    "    return pd.DataFrame([x[\"_source\"] for x in elastic_docs])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_max_mintic = fecha_ejecucion\n",
    "\n",
    "fecha_tope_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=50)-timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "datos_performance = traeRadio(fecha_max_mintic,fecha_tope_mintic)\n",
    "\n",
    "\n",
    "if datos_performance is None or datos_performance.empty:\n",
    "    while (datos_performance is None or datos_performance.empty) and ((datetime.strptime(fecha_max_mintic[0:10], '%Y-%m-%d').strftime(\"%Y-%m-%d %H:%M:%S\")) < str(now.strftime(\"%Y-%m-%d %H:%M:%S\"))):\n",
    "        fecha_max_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=50)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_tope_mintic = (datetime.strptime(fecha_tope_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=50)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        datos_performance = traeRadio(fecha_max_mintic,fecha_tope_mintic)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cruza all-cambium-device-clients con cambium-devicedevices para obtener el site_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_performance = datos_performance.rename(columns={'ap_mac':'usuarios.macRed', 'mac':'mac_usuario'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_conectados_cambium = pd.merge(datos_performance,datos_dev, on ='usuarios.macRed', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escribiendo en indice la información de tiempo promedio sesión en sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_these_keys = ['usuarios.fecha'\n",
    "                  , 'usuarios.siteID'\n",
    "                  ,'usuarios.tiempoPromedioSesionSitio'\n",
    "                  , 'usuarios.nomCentroDigital'\n",
    "                  , 'usuarios.codISO'\n",
    "                  , 'usuarios.idBeneficiario'\n",
    "                  , 'usuarios.localidad'\n",
    "                  , 'usuarios.nombreDepartamento'\n",
    "                  , 'usuarios.sistemaEnergia'\n",
    "                  , 'usuarios.nombreMunicipio'\n",
    "                  , 'usuarios.location'\n",
    "                  , 'usuarios.macRed'\n",
    "                  , 'usuarios.apGroup'\n",
    "                  #, 'usuarios.usuariosConectados'\n",
    "                  #, 'usuarios.sesiones_Usuarios'\n",
    "                  , 'usuarios.fechaControl'\n",
    "                  , 'usuarios.anyo'\n",
    "                  , 'usuarios.mes'\n",
    "                  , 'usuarios.dia'\n",
    "                  , 'usuarios.hora'\n",
    "                  , 'usuarios.minuto'\n",
    "                    , 'nombreDepartamento'\n",
    "                    , 'nombreMunicipio'\n",
    "                    , 'idBeneficiario'\n",
    "                    , 'fecha'\n",
    "                    , 'anyo'\n",
    "                    , 'mes'\n",
    "                    , 'dia'\n",
    "                  , '@timestamp']\n",
    "def doc_generator(df):\n",
    "        df_iter = df.iterrows()\n",
    "        for index, document in df_iter:\n",
    "            document = document.rename(index={'usuarios.tiempoPromedioSesionSitio_x': 'usuarios.tiempoPromedioSesionSitio','usuarios.macRed_x':'usuarios.macRed','usuarios.apGroup_x':'usuarios.apGroup','usuarios.fechaControl_x':'usuarios.fechaControl'})\n",
    "            yield {\n",
    "                    \"_index\": indice, \n",
    "                    \"_id\": f\"{str(document['usuarios.siteID']) + '-' + str(document['usuarios.fechaControl']) + '-' + str(document['usuarios.macRed'])+'-'+str(random.randrange(10000000))}\",\n",
    "                    \"_source\": filterKeys(document),\n",
    "                }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use_these_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agrupa por lugar_cod, fecha_control, mac_ap, mac_usuario y se promedia el tiempo_sesion_minutos. Este genera el campo del indice final:\n",
    "* usuarios.tiempoPromedioSesionSitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if  continuar:\n",
    "\n",
    "    try:\n",
    "\n",
    "        datos_consumos = datos_consumos.rename(columns={'lugar_cod' :'site_id'})\n",
    "        datos_consumos['mac_ap'] = datos_consumos['mac_ap'].str.replace('-',':')\n",
    "        datos_consumos['fecha_control'] = datos_consumos[\"fecha_inicio\"].str[0:-4] + '0:00'\n",
    "        tiempoPromedioSesionSitio=datos_consumos[['site_id','mac_ap','fecha_control','tiempo_sesion_minutos']].groupby(['site_id','mac_ap','fecha_control']).agg(['mean']).reset_index()\n",
    "        tiempoPromedioSesionSitio.columns = tiempoPromedioSesionSitio.columns.droplevel(1)\n",
    "        tiempoPromedioSesionSitio = tiempoPromedioSesionSitio.rename(columns={'tiempo_sesion_minutos' : 'usuarios.tiempoPromedioSesionSitio'})\n",
    "        tiempoPromedioSesionSitio['usuarios.tiempoPromedioSesionSitio'] = round(tiempoPromedioSesionSitio['usuarios.tiempoPromedioSesionSitio'],6)\n",
    "        tiempoPromedioSesionSitio = tiempoPromedioSesionSitio.rename(columns={'mac_ap' : 'usuarios.macRed'\n",
    "                                                                              ,'fecha_control' : 'usuarios.fechaControl'})\n",
    "        tiempoPromedioSesionSitio = pd.merge(tiempoPromedioSesionSitio,datos_semilla, on ='site_id', how='inner')\n",
    "        tiempoPromedioSesionSitio = pd.merge(tiempoPromedioSesionSitio, datos_dev, on=['site_id','usuarios.macRed'], how='left')\n",
    "        tiempoPromedioSesionSitio.fillna({'usuarios.apGroup':'No identificado'},inplace=True)\n",
    "\n",
    "        ##################\n",
    "        tiempoPromedioSesionSitio = tiempoPromedioSesionSitio.rename(columns={'site_id' : 'usuarios.siteID'})\n",
    "        try:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.fecha\"] = tiempoPromedioSesionSitio[\"usuarios.fechaControl\"].str[0:10]\n",
    "        except:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.fecha\"] = \"\"\n",
    "\n",
    "        try:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.anyo\"] = tiempoPromedioSesionSitio[\"usuarios.fecha\"].str[0:4]\n",
    "        except:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.anyo\"] = \"\"\n",
    "\n",
    "        try:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.mes\"] = tiempoPromedioSesionSitio[\"usuarios.fecha\"].str[5:7]\n",
    "        except:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.mes\"] = \"\"\n",
    "\n",
    "        try:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.dia\"] = tiempoPromedioSesionSitio[\"usuarios.fecha\"].str[8:10]\n",
    "        except:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.dia\"] = \"\"\n",
    "\n",
    "        try:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.hora\"] = tiempoPromedioSesionSitio[\"usuarios.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[0][\"usuarios.hora\"] = tiempoPromedioSesionSitio[\"usuarios.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[0]\n",
    "        except:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.hora\"] = \"\"\n",
    "\n",
    "        try:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.minuto\"] = tiempoPromedioSesionSitio[\"usuarios.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[1]\n",
    "        except:\n",
    "            tiempoPromedioSesionSitio[\"usuarios.minuto\"] = \"\"\n",
    "\n",
    "        tiempoPromedioSesionSitio['nombreDepartamento'] = tiempoPromedioSesionSitio['usuarios.nombreDepartamento']\n",
    "        tiempoPromedioSesionSitio['nombreMunicipio'] = tiempoPromedioSesionSitio['usuarios.nombreMunicipio']\n",
    "        tiempoPromedioSesionSitio['idBeneficiario'] = tiempoPromedioSesionSitio['usuarios.idBeneficiario']\n",
    "        tiempoPromedioSesionSitio['fecha'] = tiempoPromedioSesionSitio['usuarios.fecha']\n",
    "        tiempoPromedioSesionSitio['anyo'] = tiempoPromedioSesionSitio['usuarios.anyo']\n",
    "        tiempoPromedioSesionSitio['mes'] = tiempoPromedioSesionSitio['usuarios.mes']\n",
    "        tiempoPromedioSesionSitio['dia'] = tiempoPromedioSesionSitio['usuarios.dia']\n",
    "        tiempoPromedioSesionSitio['@timestamp'] = now.isoformat()\n",
    "        \n",
    "        salida = helpers.bulk(es, doc_generator(tiempoPromedioSesionSitio))\n",
    "\n",
    "        print(\"Fecha: \", now,\"- Tiempo promedio sesion en sitio insertado en indice principal:\",salida[0])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Fecha: \", now,\"- Nada para insertar en indice principal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escribiendo en indice la información de usuarios conectados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_these_keys = ['usuarios.fecha'\n",
    "                  , 'usuarios.siteID'\n",
    "                  #,'usuarios.tiempoPromedioSesionSitio'\n",
    "                  , 'usuarios.nomCentroDigital'\n",
    "                  , 'usuarios.codISO'\n",
    "                  , 'usuarios.idBeneficiario'\n",
    "                  , 'usuarios.localidad'\n",
    "                  , 'usuarios.nombreDepartamento'\n",
    "                  , 'usuarios.sistemaEnergia'\n",
    "                  , 'usuarios.nombreMunicipio'\n",
    "                  , 'usuarios.location'\n",
    "                  #, 'usuarios.macRed'\n",
    "                  #, 'usuarios.apGroup'\n",
    "                  , 'usuarios.usuariosConectados'\n",
    "                  , 'usuarios.sesiones_Usuarios'\n",
    "                  , 'usuarios.fechaControl'\n",
    "                  , 'usuarios.anyo'\n",
    "                  , 'usuarios.mes'\n",
    "                  , 'usuarios.dia'\n",
    "                  #, 'usuarios.hora'\n",
    "                  #, 'usuarios.minuto'\n",
    "                    , 'nombreDepartamento'\n",
    "                    , 'nombreMunicipio'\n",
    "                    , 'idBeneficiario'\n",
    "                    , 'fecha'\n",
    "                    , 'anyo'\n",
    "                    , 'mes'\n",
    "                    , 'dia'\n",
    "                  , '@timestamp']\n",
    "def doc_generator_usuconectados(df):\n",
    "        df_iter = df.iterrows()\n",
    "        for index, document in df_iter:\n",
    "            #document = document.rename(index={'usuarios.tiempoPromedioSesionSitio_x': 'usuarios.tiempoPromedioSesionSitio','usuarios.macRed_x':'usuarios.macRed','usuarios.apGroup_x':'usuarios.apGroup','usuarios.fechaControl_x':'usuarios.fechaControl'})\n",
    "            yield {\n",
    "                    \"_index\": indice, \n",
    "                    \"_id\": f\"{str(document['usuarios.siteID']) + '-' + str(document['usuarios.fechaControl']) + '-' +str(random.randrange(10000000))}\",\n",
    "                    \"_source\": filterKeys(document),\n",
    "                }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if  continuar:\n",
    "\n",
    "    try:\n",
    "        datos_logins = datos_det_conex[['fecha_control', 'site_id', 'documento']].groupby([\"fecha_control\",\"site_id\"])['documento'].nunique().reset_index()\n",
    "        datos_logins= datos_logins.rename(columns={'documento' : 'usuarios.sesiones_Usuarios'})\n",
    "\n",
    "        ###################################################################################################\n",
    "\n",
    "\n",
    "        #Se trae usuarios conectados desde cambium devices clients \n",
    "        usuariosConectados = usuarios_conectados_cambium[[\"fecha_control\",\"site_id\",\"mac_usuario\"]].groupby([\"fecha_control\",\"site_id\"]).agg(['count']).reset_index()\n",
    "        usuariosConectados.columns = usuariosConectados.columns.droplevel(1)\n",
    "        usuariosConectados= usuariosConectados.rename(columns={'mac_usuario' : 'usuarios.usuariosConectados'})\n",
    "\n",
    "\n",
    "        ###################################################################################################\n",
    "\n",
    "        usuariosConectados = pd.merge(usuariosConectados,datos_logins,  how='outer')\n",
    "        usuariosConectados.fillna({'usuarios.usuariosConectados': 0\n",
    "                                   ,'usuarios.sesiones_Usuarios' : 0 },inplace=True)\n",
    "        usuariosConectados['usuarios.usuariosConectados'] = usuariosConectados['usuarios.usuariosConectados'].astype(int)\n",
    "        usuariosConectados['usuarios.sesiones_Usuarios'] = usuariosConectados['usuarios.sesiones_Usuarios'].astype(int)\n",
    "        usuariosConectados = pd.merge(datos_semilla,  usuariosConectados, on=['site_id'], how='inner')\n",
    "        usuariosConectados = usuariosConectados.rename(columns={'fecha_control':'usuarios.fechaControl'\n",
    "                                                               ,'site_id' : 'usuarios.siteID'})\n",
    "            \n",
    "\n",
    "        try:\n",
    "            usuariosConectados[\"usuarios.fecha\"] = usuariosConectados[\"usuarios.fechaControl\"].str[0:10]\n",
    "        except:\n",
    "            usuariosConectados[\"usuarios.fecha\"] = \"\"\n",
    "\n",
    "        try:\n",
    "            usuariosConectados[\"usuarios.anyo\"] = usuariosConectados[\"usuarios.fecha\"].str[0:4]\n",
    "        except:\n",
    "            usuariosConectados[\"usuarios.anyo\"] = \"\"\n",
    "\n",
    "        try:\n",
    "            usuariosConectados[\"usuarios.mes\"] = usuariosConectados[\"usuarios.fecha\"].str[5:7]\n",
    "        except:\n",
    "            usuariosConectados[\"usuarios.mes\"] = \"\"\n",
    "\n",
    "        try:\n",
    "            usuariosConectados[\"usuarios.dia\"] = usuariosConectados[\"usuarios.fecha\"].str[8:10]\n",
    "        except:\n",
    "            usuariosConectados[\"usuarios.dia\"] = \"\"\n",
    "\n",
    "        \n",
    "\n",
    "        usuariosConectados['nombreDepartamento'] = usuariosConectados['usuarios.nombreDepartamento']\n",
    "        usuariosConectados['nombreMunicipio'] = usuariosConectados['usuarios.nombreMunicipio']\n",
    "        usuariosConectados['idBeneficiario'] = usuariosConectados['usuarios.idBeneficiario']\n",
    "        usuariosConectados['fecha'] = usuariosConectados['usuarios.fecha']\n",
    "        usuariosConectados['anyo'] = usuariosConectados['usuarios.anyo']\n",
    "        usuariosConectados['mes'] = usuariosConectados['usuarios.mes']\n",
    "        usuariosConectados['dia'] = usuariosConectados['usuarios.dia']\n",
    "        usuariosConectados['@timestamp'] = now.isoformat()\n",
    "\n",
    "\n",
    "        salida = helpers.bulk(es, doc_generator_usuconectados(usuariosConectados))\n",
    "\n",
    "        print(\"Fecha: \", now,\"- Usuarios Conectados y dispositivos conectados en sitio insertado en indice principal:\",salida[0])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Fecha: \", now,\"- Nada para insertar en indice principal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando fecha para control de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se actualiza la fecha de control. Si el calculo supera la fecha hora actual, se asocia esta ultima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_ejecucion = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=50)).strftime(\"%Y-%m-%d %H:%M:%S\")[0:15] + '0:00'    \n",
    "\n",
    "if fecha_ejecucion > str(now.strftime('%Y-%m-%d %H:%M:%S'))[0:15] + '0:00':\n",
    "    fecha_ejecucion = str(now.strftime('%Y-%m-%d %H:%M:%S'))[0:15] + '0:00'\n",
    "response = es.index(\n",
    "        index = indice_control,\n",
    "        id = 'jerarquia-tablero07',\n",
    "        body = { 'jerarquia-tablero07': 'jerarquia-tablero07','usuarios.Tablero07.fechaControl' : fecha_ejecucion}\n",
    ")\n",
    "print(\"actualizada fecha control de ejecucion:\",fecha_ejecucion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
