{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Que hace este script?\n",
    "* Calcula para cada AP: trafico.totales.totalConexiones\n",
    "* Calcula para cada site id: trafico.concurrenciaConexiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from ssl import create_default_context\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import parametros\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectando a ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ultima línea se utiliza para garantizar la ejecución de la consulta\n",
    "* timeout es el tiempo para cada ejecución\n",
    "* max_retries el número de intentos si la conexión falla\n",
    "* retry_on_timeout para activar los reitentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = create_default_context(cafile=parametros.cafile)\n",
    "es = Elasticsearch(\n",
    "    parametros.servidor,\n",
    "    http_auth=(parametros.usuario_EC, parametros.password_EC),\n",
    "    scheme=\"https\",\n",
    "    port=parametros.puerto,\n",
    "    ssl_context=context,\n",
    "    timeout=60, max_retries=3, retry_on_timeout=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando fechas para la ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se calculan las fechas para asociar al nombre del indice\n",
    "* fecha_hoy es usada para concatenar al nombre del indice principal previa inserción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "fecha_hoy = str(now.strftime(\"%Y.%m.%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiendo indice principal con fecha de hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'parametros' has no attribute 'conteo_centros_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7134ac06c488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparametros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconteo_centros_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mindice_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparametros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtableros_mintic_control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'parametros' has no attribute 'conteo_centros_index'"
     ]
    }
   ],
   "source": [
    "indice = parametros.conteo_centros_index\n",
    "indice_control = parametros.tableros_mintic_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para generar JSON compatible con ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterKeys(document):\n",
    "    return {key: document[key] for key in use_these_keys }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leyendo indice semilla-inventario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el script que ingesta semilla, trae la información de los centros de conexión administrados. Para el indice principal se requiere:\n",
    "\n",
    "* site_id como llave del centro de conexión.\n",
    "* Datos geográficos (Departamento, municipio, centro poblado, sede, energía, latitud, longitud, COD_ISO, entre otros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 10000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= parametros.semilla_inventario_index,\n",
    "        body={\n",
    "               \"_source\": ['site_id','nombre_municipio', 'nombre_departamento', 'nombre_centro_pob', 'nombreSede' \n",
    "                           , 'energiadesc', 'latitud', 'longitud','COD_ISO','id_Beneficiario']\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "\n",
    "    datos_semilla = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) pd.DataFrame(fields)\n",
    "except:\n",
    "    print(\"fecha:\",now,\"- Error en lectura de datos semilla\")\n",
    "    #exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leyendo indice cambium-devicedevices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee la información de los dispositivos de red monitoreados por Cambium. En esta lectura no hay referencia de fechas ya que solo hay una ocurrencia por MAC de dispositivo de red.\n",
    "\n",
    "* site_id es la llave para cruzar con cada centro de conexión.\n",
    "* mac, IP y name son datos básicos del dispositivo.\n",
    "* ap_group identifica los dispositivos como INDOOR u OUTDOOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 30000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= parametros.cambium_d_d_index,\n",
    "        body={\n",
    "                    \"_source\": [\"site_id\",\"mac\",\"ip\",\"ap_group\",\"name\",\"status\"]  \n",
    "                  , \"query\": {\n",
    "                    \"match_all\": {}\n",
    "                  }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "\n",
    "    datos_dev = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\n",
    "except:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se descartan registros con site_id vacios y se limpian los NaN del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev.dropna(subset=['site_id'])\n",
    "datos_dev.fillna('', inplace=True)\n",
    "datos_dev = datos_dev.drop(datos_dev[(datos_dev['site_id']=='')].index)\n",
    "datos_dev.sort_values(['site_id','ap_group'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se limpian valores errados de ap group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev['ap_group'] = datos_dev['ap_group'].str.split(\"-\", n = 1, expand = True)[0]\n",
    "datos_dev['ap_group'] = datos_dev['ap_group'].str.split(\"_\", n = 1, expand = True)[0]\n",
    "datos_dev = datos_dev.drop(datos_dev[(datos_dev['ap_group']=='')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE borran duplicados por MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev = datos_dev.drop_duplicates('mac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se renombran campos según estructura del indice final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev = datos_dev.rename(columns={'ap_mac' : 'trafico.macRed','ap_group': 'trafico.apGroup'\n",
    "                                        , 'ip': 'trafico.IP'\n",
    "                                        , 'mac' : 'trafico.macRed'\n",
    "                                        , 'name' : 'trafico.deviceName'\n",
    "                                        , 'status' : 'trafico.status.macRed'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiando nombre de campos y generando location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se valida latitud y longitud. Luego se calcula campo location\n",
    "* Se renombran los campos de semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(x):\n",
    "    patron = re.compile('^(\\-?\\d+(\\.\\d+)?),\\s*(\\-?\\d+(\\.\\d+)?)$') #patrón que debe cumplir\n",
    "    if (not patron.match(x) is None):\n",
    "        return x.replace(',','.')\n",
    "    else:\n",
    "        #Código a ejecutar si las coordenadas no son válidas\n",
    "        return 'a'\n",
    "datos_semilla['latitud'] = datos_semilla['latitud'].apply(get_location)\n",
    "datos_semilla['longitud'] = datos_semilla['longitud'].apply(get_location)\n",
    "datos_semilla['trafico.location'] = datos_semilla['latitud'] + ',' + datos_semilla['longitud']\n",
    "datos_semilla['trafico.location']=datos_semilla['trafico.location'].str.replace('a,a','')\n",
    "datos_semilla.drop(columns=['latitud','longitud'],inplace=True)\n",
    "\n",
    "datos_semilla = datos_semilla.rename(columns={'nombre_municipio': 'trafico.nombreMunicipio'\n",
    "                                              , 'nombre_departamento' : 'trafico.nombreDepartamento'\n",
    "                                              , 'nombre_centro_pob': 'trafico.localidad'\n",
    "                                              , 'nombreSede' : 'trafico.nomCentroDigital'\n",
    "                                              , 'energiadesc' : 'trafico.sistemaEnergia'\n",
    "                                              , 'COD_ISO' : 'trafico.codISO'\n",
    "                                              , 'id_Beneficiario' : 'trafico.idBeneficiario'})\n",
    "datos_semilla.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se lee información para usuarios recurrencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula y agrega al indice principal:\n",
    "* trafico.concurrenciaConexiones\n",
    "\n",
    "Se lee el indice recurrencia de conexiones y se compara con el flujo detalle conexiones para el rango dado. Si cruzan, se suma a la cuenta de recurrentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 5000000\n",
    "response = es.search(\n",
    "    index= parametros.ohmyfi_r_u_index,\n",
    "    body={\n",
    "            \"_source\": [\"ultima_conexion\", \"lugar_cod\", \"id_usuario\"]\n",
    "    },\n",
    "    size=total_docs\n",
    ")\n",
    "#print(es.info())\n",
    "elastic_docs = response[\"hits\"][\"hits\"]\n",
    "fields = {}\n",
    "for num, doc in enumerate(elastic_docs):\n",
    "    source_data = doc[\"_source\"]\n",
    "    for key, val in source_data.items():\n",
    "        try:\n",
    "            fields[key] = np.append(fields[key], val)\n",
    "        except KeyError:\n",
    "            fields[key] = np.array([val])\n",
    "\n",
    "datos_recurrencia = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cuenta la cantidad de usuarios con mas de una conexión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrencia usuario a indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_these_keys = ['trafico.nomCentroDigital',\n",
    "                  'trafico.codISO',\n",
    "                  'trafico.localidad',\n",
    "                  'trafico.siteID',\n",
    "                  'trafico.codISO',\n",
    "                  'trafico.nombreDepartamento',\n",
    "                  'trafico.sistemaEnergia',\n",
    "                  'trafico.nombreMunicipio',\n",
    "                  'trafico.idBeneficiario',\n",
    "                  'trafico.totales.fechaControl',\n",
    "                  'trafico.concurrenciaConexiones',\n",
    "                  'trafico.totales.fecha',\n",
    "                  'trafico.totales.anyo',\n",
    "                  'trafico.totales.mes',\n",
    "                  'trafico.totales.dia',\n",
    "                  'trafico.totales.hora',\n",
    "                  'trafico.totales.minuto',\n",
    "                  'nombreDepartamento',\n",
    "                    'nombreMunicipio',\n",
    "                    'idBeneficiario',\n",
    "                    'fecha',\n",
    "                    'anyo',\n",
    "                    'mes',\n",
    "                    'dia',\n",
    "                  '@timestamp']\n",
    "def doc_generator(df):\n",
    "    df_iter = df.iterrows()\n",
    "    for index, document in df_iter:\n",
    "        yield {\n",
    "                \"_index\": indice, \n",
    "                \"_id\": f\"{'Concurrencia-' + document['trafico.siteID'] + '-' +document['trafico.totales.fechaControl']}\",\n",
    "                \"_source\": filterKeys(document),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    datos_det_conex_completo.rename(columns={'mac_usuario':'id_usuario'}, inplace=True)\n",
    "    aux_recurrencia=datos_det_conex_completo[['lugar_cod','id_usuario']].groupby(['id_usuario']).agg(['count']).reset_index()\n",
    "    aux_recurrencia.columns = aux_recurrencia.columns.droplevel(1)\n",
    "    aux_recurrencia.rename(columns={'lugar_cod': 'contador'}, inplace=True)\n",
    "    aux_recurrencia = aux_recurrencia.drop(aux_recurrencia[(aux_recurrencia['contador'] < 2)].index)\n",
    "    datos_recurrencia = pd.merge(datos_det_conex_completo,  aux_recurrencia, on='id_usuario', how='inner')\n",
    "    datos_recurrencia = datos_recurrencia[['lugar_cod','fecha_control','id_usuario']].groupby(['lugar_cod','fecha_control']).agg(['count']).reset_index()\n",
    "    datos_recurrencia.columns = datos_recurrencia.columns.droplevel(1)\n",
    "    datos_recurrencia.rename(columns={'lugar_cod':'site_id'}, inplace=True)\n",
    "    datos_recurrencia = pd.merge(datos_semilla,  datos_recurrencia, on='site_id', how='inner')\n",
    "    datos_recurrencia.rename(columns={'site_id':'trafico.siteID'\n",
    "                                     ,'id_usuario': 'trafico.concurrenciaConexiones'\n",
    "                                     ,'fecha_control' : 'trafico.totales.fechaControl'}, inplace=True)\n",
    "    datos_recurrencia.fillna({'trafico.concurrenciaConexiones':0},inplace=True)\n",
    "    datos_recurrencia.fillna('', inplace=True)\n",
    "    datos_recurrencia[\"trafico.totales.fecha\"] = datos_recurrencia[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[0]\n",
    "    datos_recurrencia[\"trafico.totales.anyo\"] = datos_recurrencia[\"trafico.totales.fecha\"].str[0:4]\n",
    "    datos_recurrencia[\"trafico.totales.mes\"] = datos_recurrencia[\"trafico.totales.fecha\"].str[5:7]\n",
    "    datos_recurrencia[\"trafico.totales.dia\"] = datos_recurrencia[\"trafico.totales.fecha\"].str[8:10]\n",
    "    datos_recurrencia[\"trafico.totales.hora\"] = datos_recurrencia[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[0]\n",
    "    datos_recurrencia[\"trafico.totales.minuto\"] = datos_recurrencia[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[1]\n",
    "    \n",
    "    datos_recurrencia['nombreDepartamento'] = datos_recurrencia['trafico.nombreDepartamento']\n",
    "    datos_recurrencia['nombreMunicipio'] = datos_recurrencia['trafico.nombreMunicipio']\n",
    "    datos_recurrencia['idBeneficiario'] = datos_recurrencia['trafico.idBeneficiario']\n",
    "    datos_recurrencia['fecha'] = datos_recurrencia['trafico.totales.fecha']\n",
    "    datos_recurrencia['anyo'] = datos_recurrencia['trafico.totales.anyo']\n",
    "    datos_recurrencia['mes'] = datos_recurrencia['trafico.totales.mes']\n",
    "    datos_recurrencia['dia'] = datos_recurrencia['trafico.totales.dia']\n",
    "    \n",
    "    datos_recurrencia['@timestamp'] = now.isoformat() \n",
    "    salida = helpers.bulk(es, doc_generator(datos_recurrencia))\n",
    "    print(\"Fecha: \", now,\"- Datos Concurrencia de conexiones en indice principal:\",salida[0])\n",
    "except:\n",
    "    print(\"Fecha: \", now,\"- No hay datos de concurrencia de conexiones para insetar en indice principal:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando fecha para control de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se actualiza la fecha de control. Si el calculo supera la fecha hora actual, se asocia esta ultima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_ejecucion = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=10)).strftime(\"%Y-%m-%d %H:%M:%S\")[0:15] + '0:00'    \n",
    "\n",
    "if fecha_ejecucion > str(now.strftime('%Y-%m-%d %H:%M:%S'))[0:15] + '0:00':\n",
    "    fecha_ejecucion = str(now.strftime('%Y-%m-%d %H:%M:%S'))[0:15] + '0:00'\n",
    "response = es.index(\n",
    "        index = indice_control,\n",
    "        id = 'jerarquia_trafico_conexiones',\n",
    "        body = { 'jerarquia_trafico_conexiones': 'trafico_conexiones','trafico.fechaControl' : fecha_ejecucion}\n",
    ")\n",
    "print(\"actualizada fecha control de ejecucion:\",fecha_ejecucion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
