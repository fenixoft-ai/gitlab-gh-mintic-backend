{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from ssl import create_default_context\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import parametros\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_start = perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectando a ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ultima línea se utiliza para garantizar la ejecución de la consulta<br>\n",
    "* timeout es el tiempo para cada ejecución\n",
    "* max_retries el número de intentos si la conexión falla<br>\n",
    "* retry_on_timeout para activar los reitentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = create_default_context(cafile=parametros.cafile)\n",
    "es = Elasticsearch(\n",
    "    parametros.servidor,\n",
    "    http_auth=(parametros.usuario_EC, parametros.password_EC),\n",
    "    scheme=\"https\",\n",
    "    port=parametros.puerto,\n",
    "    ssl_context=context,\n",
    "    timeout=120, max_retries=3, retry_on_timeout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para realizar consultas cuando la cantidad de registros es mayor a 10.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scan(query, index, total_docs, client):\n",
    "    \n",
    "    results = helpers.scan(client, index=index, query=query)\n",
    "    \n",
    "    data = []\n",
    "    for item in results:\n",
    "        data.append(item['_source'])\n",
    "        if len(data) >= total_docs:\n",
    "            break\n",
    "    \n",
    "    data = pd.DataFrame(data)\n",
    "    print(data)\n",
    "    # return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando fechas para la ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se calculan las fechas para asociar al nombre del indice<br>\n",
    "* fecha_hoy es usada para concatenar al nombre del indice principal previa inserción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "fecha_hoy = str(now.strftime(\"%Y.%m.%d\"))\n",
    "ahora_format = \"%Y-%m-%d\"'T'\"%H:%M:%S\"\n",
    "ahora = str(now.strftime(ahora_format))\n",
    "ahora_cdd = str(now.strftime(\"%Y-%m-%d\"' '\"%H:%M:%S\"))\n",
    "fechaAhora = str(now.strftime(\"%Y%m%d%H%M%S\"))\n",
    "datos_logs =\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiendo indice principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = parametros.disponibilidad_tableros_index\n",
    "indice_control = parametros.tableros_mintic_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dev-disponibilidad-tableros'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para generar JSON compatible con ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterKeys(document, use_these_keys):\n",
    "    return {key: document.get(key) for key in use_these_keys }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trae la ultima fecha para control de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando en el rango de tiempo de la ejecución, no se insertan nuevos valores, la fecha maxima en indice mintic no aumenta, por tanto se usa esta fecha de control para garantizar que incremente el bucle de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultima fecha para control de ejecucion gestion_estado_incidentes: 2021-07-01T09:00:00\n"
     ]
    }
   ],
   "source": [
    "total_docs = 1\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= indice_control,\n",
    "        body={\n",
    "           \"_source\": [\"gestion.fechaControl\"],\n",
    "              \"query\": {\n",
    "                \"bool\": {\n",
    "                  \"filter\": [\n",
    "                  {\n",
    "                    \"exists\": {\n",
    "                              \"field\":\"jerarquia_disponibilidad1\"\n",
    "                    }\n",
    "                  }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        fecha_ejecucion = doc[\"_source\"]['gestion.fechaControl']\n",
    "except:\n",
    "    response[\"hits\"][\"hits\"] = []\n",
    "if response[\"hits\"][\"hits\"] == []:\n",
    "    fecha_ejecucion = '2021-06-01T00:00:00'\n",
    "print(\"ultima fecha para control de ejecucion gestion_estado_incidentes:\",fecha_ejecucion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- leyendo indice semilla-inventario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el script que ingesta semilla, trae la información de los centros de conexión administrados. Para el indice principal se requiere:<br>\n",
    "<br>\n",
    "* site_id como llave del centro de conexión.<br>\n",
    "* Datos geográficos (Departamento, municipio, centro poblado, sede.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 10000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= parametros.semilla_inventario_index,\n",
    "        body={\n",
    "               \"_source\": ['site_id','nombre_municipio', 'nombre_departamento', 'nombre_centro_pob','energiadesc'\n",
    "                           ,'nombreSede','latitud','longitud','id_Beneficiario','COD_ISO','codDanesede',\n",
    "                           'cod_servicio','codDaneMuni','nombre_centro_pob','codCentroPoblado','codDaneInstitucionEdu',\n",
    "                           'tipoSitio','detalleSitio','energia','region','matricula','DDA','grupoDesc','estadoInstalacion',\n",
    "                           'nombreInstitucionEd']\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "\n",
    "    datos_semilla = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"fecha:\",now,\"- Error en lectura de datos semilla\")\n",
    "    #exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(x,y='lat'):\n",
    "    patron = re.compile('^(\\-?\\d+(\\.\\d+)?),\\s*(\\-?\\d+(\\.\\d+)?)$') #patrón que debe cumplir\n",
    "    if (not patron.match(x) is None) and (str(x)!=''):\n",
    "        return x.replace(',','.')\n",
    "    else:\n",
    "        #Código a ejecutar si las coordenadas no son válidas\n",
    "        return '4.596389' if y=='lat' else '-74.074639'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_semilla['latitud'] = datos_semilla['latitud'].apply(lambda x:get_location(x,'lat'))\n",
    "datos_semilla['longitud'] = datos_semilla['longitud'].apply(lambda x:get_location(x,'lon'))\n",
    "datos_semilla = datos_semilla.drop(datos_semilla[(datos_semilla[\"longitud\"]=='a') | (datos_semilla[\"latitud\"]=='a')].index)\n",
    "datos_semilla['gestion.location'] = datos_semilla['latitud'] + ',' + datos_semilla['longitud']\n",
    "datos_semilla['gestion.location']=datos_semilla['gestion.location'].str.replace('a,a','')\n",
    "datos_semilla.drop(columns=['latitud','longitud'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Leyendo datos de Cambium-Device-Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se extraen los datos de 'cambium-devicedevices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traerDDevices(client):\n",
    "    \n",
    "    total_docs = 30000\n",
    "    try:\n",
    "        query = {\n",
    "            \"_source\": [\n",
    "                \"registration_date\", \"mac\", \"ip\", \"ap_group\", \n",
    "                \"site_id\", \"status\", \"name\"\n",
    "            ],\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        datos_DDevices = custom_scan(\n",
    "            query, \n",
    "            parametros.cambium_d_d_index,\n",
    "            total_docs=30000, \n",
    "            client=client\n",
    "        )\n",
    "        \n",
    "        datos_DDevices['site_id'] = datos_DDevices['site_id'].str.strip()\n",
    "        datos_DDevices  = datos_DDevices.rename(columns={'ap_group':'gestion.ptos_acceso'})\n",
    "        datos_DDevices  = datos_DDevices.dropna(subset=['site_id'])\n",
    "        datos_DDevices.fillna('', inplace=True)\n",
    "        datos_DDevices = datos_DDevices.drop(datos_DDevices[(datos_DDevices['site_id']=='')].index)\n",
    "        datos_DDevices.sort_values(['site_id','gestion.ptos_acceso'], inplace=True)\n",
    "        \n",
    "        datos_DDevices['gestion.ptos_acceso'] = datos_DDevices['gestion.ptos_acceso'].str.split(\"-\", n = 1, expand = True)[0]\n",
    "        datos_DDevices['gestion.ptos_acceso'] = datos_DDevices['gestion.ptos_acceso'].str.split(\"_\", n = 1, expand = True)[0]\n",
    "        datos_DDevices['gestion.ptos_acceso'] = datos_DDevices['gestion.ptos_acceso'].str.split(\".\", n = 1, expand = True)[0]\n",
    "        datos_DDevices = datos_DDevices.drop(datos_DDevices[(datos_DDevices['gestion.ptos_acceso']=='')].index)\n",
    "        datos_DDevices = datos_DDevices.drop_duplicates('mac')\n",
    "        \n",
    "        return datos_DDevices \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return pd.DataFrame()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando bucle hasta conseguir datos de servicemanager-incidentes o hasta la fecha actual para realizar la carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_invalid_values(df, fields=[], values = ['NA','',np.NaN,None],operator='or'):\n",
    "    fields = df.columns if fields==[] else fields\n",
    "    if operator=='or':\n",
    "        freduce = np.logical_or.reduce\n",
    "    elif operator=='and':\n",
    "        freduce = np.logical_and.reduce\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    df.drop(df[freduce([df[c].isin(values) for c in fields])].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_CDD=pd.DataFrame(columns=['registration_date', \n",
    "                                    'gestion.ptos_acceso', \n",
    "                                    'ip', \n",
    "                                    'site_id', \n",
    "                                    'mac',\n",
    "                                    'status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         registration_date              ap_group              ip  \\\n",
      "0      2021-04-07 19:13:54  INDOOR-44745-ZGYO227  172.28.118.179   \n",
      "1      2021-04-07 19:38:50               OUTDOOR  172.28.118.180   \n",
      "2      2021-04-08 10:50:15               OUTDOOR  172.28.118.181   \n",
      "3      2021-04-19 10:46:35  INDOOR_44747-ZGYO413  172.28.118.171   \n",
      "4      2021-04-19 10:46:34               OUTDOOR  172.28.118.172   \n",
      "...                    ...                   ...             ...   \n",
      "21118  2021-12-17 15:11:03               OUTDOOR  172.25.227.228   \n",
      "21119  2021-12-17 15:13:36               OUTDOOR  172.25.227.229   \n",
      "21120  2021-12-17 15:10:22  INDOOR_52005-ZCKE815  172.25.227.227   \n",
      "21121  2021-12-17 14:46:38               OUTDOOR  172.25.229.197   \n",
      "21122  2021-12-01 14:23:38                                         \n",
      "\n",
      "                           name        site_id                mac      status  \n",
      "0          44745-ZGYO227-AP-INT  44745-ZGYO227  BC:E6:7C:5E:66:88      online  \n",
      "1         44745-ZGYO227-AP-EXT2  44745-ZGYO227  58:C1:7A:E9:C9:6F      online  \n",
      "2         44745-ZGYO227-AP-EXT1  44745-ZGYO227  58:C1:7A:E9:C8:5C      online  \n",
      "3          44747-ZGYO413-AP-INT  44747-ZGYO413  BC:E6:7C:ED:F2:4F      online  \n",
      "4        44747-ZGYO413-AP-EXT-1  44747-ZGYO413  BC:E6:7C:4F:07:88      online  \n",
      "...                         ...            ...                ...         ...  \n",
      "21118     52005-ZCKE815-AP-EXT1  52005-ZCKE815  BC:A9:93:69:B0:A8     offline  \n",
      "21119     52005-ZCKE815-AP-EXT2  52005-ZCKE815  BC:A9:93:6A:2C:B8     offline  \n",
      "21120      52005-ZCKE815-AP-INT  52005-ZCKE815  BC:E6:7C:5D:88:57     offline  \n",
      "21121     19327-ZCKE884-AP-EXT2  19327-ZCKE884  BC:A9:93:67:75:B0     offline  \n",
      "21122  ePMP 1000 Hotspot-18B320  21836-ZGYO922  58:C1:7A:18:B3:20  onboarding  \n",
      "\n",
      "[21123 rows x 7 columns]\n",
      "'NoneType' object is not subscriptable\n",
      "Duration 1.138221169821918 seconds.\n"
     ]
    }
   ],
   "source": [
    "t1 = perf_counter()\n",
    "\n",
    "datos_CDD = traerDDevices(es)\n",
    "\n",
    "t2 = perf_counter()\n",
    "print(f'Duration {t2 - t1} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datos_CDD.empty:\n",
    "    datos_CDD=pd.DataFrame(columns=['registration_date', \n",
    "                                    'gestion.ptos_acceso', \n",
    "                                    'ip', \n",
    "                                    'site_id', \n",
    "                                    'mac',\n",
    "                                    'status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datos_CDD is None or datos_CDD.empty:\n",
    "    datos_logs = datos_logs +\"\\n No trajo datos en este rango de fecha. \"\n",
    "    datos_CDD2=pd.DataFrame(columns=['site_id', 'status'])\n",
    "else:\n",
    "    drop_invalid_values(datos_CDD,['gestion.ptos_acceso','site_id','status'])\n",
    "    \n",
    "    datos_CDD  = datos_CDD.dropna(subset=['site_id'])\n",
    "\n",
    "    datos_CDD = datos_CDD.drop(datos_CDD[(datos_CDD['site_id']=='')].index)\n",
    "    datos_logs= datos_logs + \"\\n total reg.: \" + str(datos_CDD[\"site_id\"].size) + \"    viene con (registration_date,gestion.ptos_acceso,ip,site_id,mac,status)\"\n",
    "\n",
    "    #datos_CDD2 = datos_CDD[[\"site_id\",\"registration_date\", \"status\", \"gestion.ptos_acceso\"]]\n",
    "    datos_CDD2 = datos_CDD[[\"site_id\", \"status\"]]    #datos_CDD2 = datos_CDD2[[\"site_id\",\"registration_date\", \"status\", \"gestion.ptos_acceso\"]].groupby([\"site_id\", \"status\", \"gestion.ptos_acceso\"]).agg(['max']).reset_index()\n",
    "    datos_CDD2 = datos_CDD2[[\"site_id\",\"status\"]].groupby([\"site_id\"]).agg(['count']).reset_index()\n",
    "\n",
    "    datos_CDD2.columns = datos_CDD2.columns.droplevel(1)       \n",
    "    datos_logs = datos_logs +\"\\n se quitan los repetidos status=(offline, online, onboaring) total reg.: \" + str(datos_CDD2[\"site_id\"].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disponibilidad(x):\n",
    "    resp = 'No disponible'\n",
    "    if 'online' in list(x):\n",
    "        resp='Disponible'\n",
    "    return resp\n",
    "\n",
    "df_dispo = pd.concat([datos_CDD.groupby(['site_id'])['status'].apply(lambda x: disponibilidad(x)),\n",
    "                      datos_CDD.groupby(['site_id']).registration_date.max('registration_date')],\n",
    "                      axis=1)\n",
    "\n",
    "\n",
    "df_dispo.rename(columns={'status':'disponibilidad','registration_date':'max_fecha'},inplace=True)\n",
    "\n",
    "df_dispo.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "df_dispo= pd.merge(df_dispo,datos_CDD[['site_id','mac','ip','gestion.ptos_acceso','status']],on=['site_id'],how='inner')\n",
    "\n",
    "df_dispo.rename(columns={'status':'status.macRed','gestion.ptos_acceso':'ap_group'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se limpian datos mal formados de ap_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_dispo.empty:\n",
    "    df_dispo['ap_group'] = df_dispo['ap_group'].str.split(\"-\", n = 1, expand = True)[0]\n",
    "    df_dispo['ap_group'] = df_dispo['ap_group'].str.split(\"_\", n = 1, expand = True)[0]\n",
    "    df_dispo['ap_group'] = df_dispo['ap_group'].str.split(\".\", n = 1, expand = True)[0]\n",
    "    df_dispo = df_dispo.drop(df_dispo[(df_dispo['ap_group']=='')].index)\n",
    "    df_dispo = df_dispo.drop(df_dispo[(df_dispo['ap_group']=='PRUEBA OUTDOOR')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de estados<br>\n",
    "* estos estados guardan el ultimo estado \"offline\" en que estuvo el centro <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 10000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= \"edo_sitio-\" + indice,\n",
    "        body={\n",
    "               \"_source\": ['site_id','fechahora','itsm_incident_id']\n",
    "        },\n",
    "        size=total_docs\n",
    "    )    \n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "\n",
    "    edo_sitio = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ]))\n",
    "    \n",
    "    if edo_sitio.empty:\n",
    "        edo_sitio = pd.DataFrame(columns=['site_id','fechahora','itsm_incident_id'])\n",
    "\n",
    "except Exception as e:\n",
    "    edo_sitio = pd.DataFrame(columns=['site_id','fechahora','itsm_incident_id'])\n",
    "    \n",
    "edo_sitio[\"fechahora\"] = fechaAhora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    concat0 = pd.merge(datos_semilla, datos_CDD , on=['site_id'],how='inner')\n",
    "except Exception as e:\n",
    "#     print(e.message)\n",
    "    concat0 = pd.DataFrame()\n",
    "\n",
    "datos_logs = datos_logs +\"\\n se cruza con SEMILLA  total reg.: \" + str(concat0[\"site_id\"].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo merge entre semilla e incidentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esto es el deber ser, lo politicamente correcto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(concat0.empty):\n",
    "    fecha_ejecucion = (datetime.strptime(fecha_ejecucion, \"%Y-%m-%d\"'T'\"%H:%M:%S\")+timedelta(minutes=60)).strftime(\"%Y-%m-%d\"'T'\"%H:%M:%S\")[0:15] + '0:00'\n",
    "\n",
    "    if fecha_ejecucion > str(now.strftime(\"%Y-%m-%d\"'T'\"%H:%M:%S\"))[0:15] + '0:00':\n",
    "        fecha_ejecucion = str(now.strftime(\"%Y-%m-%d\"'T'\"%H:%M:%S\"))[0:15] + '0:00'\n",
    "\n",
    "    response = es.index(\n",
    "        index = indice_control,\n",
    "        id = 'jerarquia_disponibilidad1',\n",
    "        body = { 'jerarquia_disponibilidad1': 'jerarquia_disponibilidad1','gestion.fechaControl' : fecha_ejecucion}\n",
    "    )\n",
    "    print(\"actualizada fecha control de ejecucion:\",fecha_ejecucion)\n",
    "    exit()\n",
    "\n",
    "result1=concat0\n",
    "result2=concat0\n",
    "\n",
    "result1['cantidad'] = 0\n",
    "result2['cantidad'] = 0\n",
    "\n",
    "result1 = result1.groupby(['site_id'])['site_id'].count().to_frame()\n",
    "result2 = result2.groupby(['site_id', 'status'])['site_id'].count().to_frame()\n",
    "\n",
    "result1 = result1.rename(columns={'site_id' :  'cantidad_x'})\n",
    "result2 = result2.rename(columns={'site_id' :  'cantidad_y'})\n",
    "result1 = result1.reset_index()\n",
    "result2 = result2.reset_index()\n",
    "#result1 = result1[['site_id',\"cantidad\"]].groupby(['site_id']).agg(['count'])\n",
    "#result2 = result2[['site_id', 'status',\"cantidad\"]].groupby(['site_id', 'status']).agg(['count'])\n",
    "#result1 = result1.columns.droplevel(1)\n",
    "#result2 = result2.columns.droplevel(1)\n",
    "#datos_CDD2[[\"site_id\",\"status\"]].groupby([\"site_id\"]).agg(['count']).reset_index()\n",
    "result_completo = pd.merge(result1, result2,on=['site_id'],how='inner')\n",
    "#result_completo[\"gestion.estadoCentro\"] = result_completo.apply(lambda row: 'DESCONECTADOS' if( row.status == 'offline' and row.cantidad_x == row.cantidad_y) else 'CONECTADOS', axis=1)\n",
    "result_completo[\"gestion.estadoCentro\"] = result_completo.apply(lambda row: 'DESCONECTADOS' if( row.status  == 'offline' and row.cantidad_x == row.cantidad_y) else 'CONECTADOS', axis=1)\n",
    "\n",
    "completo  = pd.merge(concat0, result_completo,on=['site_id'],how='inner')\n",
    "\n",
    "\n",
    "#completo \n",
    "conectados = 0\n",
    "desconectados = 0\n",
    "\n",
    "bb = completo[(completo[\"gestion.estadoCentro\"]==\"DESCONECTADOS\")].reset_index()\n",
    "aa = completo[(completo[\"gestion.estadoCentro\"]!=\"DESCONECTADOS\")].reset_index()\n",
    "\n",
    "conectados = aa[\"site_id\"].size\n",
    "desconectados = bb[\"site_id\"].size\n",
    "totales = desconectados + conectados\n",
    "print (\" Conectados: \" , conectados , \" desconectados: \", desconectados , \" total: \" , totales)\n",
    "print(completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.- insercion en el indice<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primero INSERTAR FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo.fillna({'fechahora':fechaAhora},inplace=True)\n",
    "completo.fillna({'gestion.estadoCentro':'CONECTADOS'},inplace=True)\n",
    "completo.fillna({'itsm_incident_id':0},inplace=True)\n",
    "\n",
    "try:\n",
    "    completo = completo.rename(columns={'id_Beneficiario' :  'gestion.estado.id_Beneficiario'\n",
    "                                                                ,'nombreSede':'gestion.estado.nombreSede'\n",
    "                                                                ,'site_id':'gestion.estado.site_id'\n",
    "                                                                ,'nombre_departamento':'gestion.estado.dptoGestion'\n",
    "                                                                ,'nombre_municipio':'gestion.estado.muniGestion'\n",
    "                                                                ,'nombre_centro_pob':'gestion.estado.nombre_centro_pob'\n",
    "                                                                ,'COD_ISO':'gestion.estado.COD_ISO'\n",
    "                                                                ,'codDanesede':'gestion.estado.codDanesede'\n",
    "                                                                ,'energiadesc':'gestion.estado.energiadesc'\n",
    "                                                                ,'DDA':'gestion.estado.DDA'\n",
    "                                                                ,'gestion.location':'gestion.estado.location'\n",
    "                                                                ,'estadoInstalacion':'gestion.estado.estadoInstalacion'\n",
    "                                                                ,'nombreInstitucionEd':'gestion.estado.nombreInstitucionEd'\n",
    "                                                                ,'matricula':'gestion.estado.matricula'\n",
    "                                                                ,'municipioPDET':'gestion.estado.municipioPDET'    \n",
    "                                        ,'cod_servicio':'gestion.estado.cod_servicio'\n",
    "                                        ,'codDaneMuni':'gestion.estado.codDaneMuni'\n",
    "                                        ,'codCentroPoblado':'gestion.estado.codCentroPoblado'\n",
    "                                        ,'codDaneInstitucionEdu':'gestion.estado.codDaneInstitucionEdu'\n",
    "                                        ,'tipoSitio':'gestion.estado.tipoSitio'\n",
    "                                        ,'detalleSitio':'gestion.estado.detalleSitio'\n",
    "                                        ,'energia':'gestion.estado.energia'\n",
    "                                        ,'region':'gestion.estado.region'\n",
    "                                        ,'grupoDesc' :'gestion.estado.grupoDesc'\n",
    "                                        })\n",
    "                \n",
    "    completo[\"gestion.fechaControl\"] =  ahora_cdd\n",
    "    completo[\"gestion.fecha\"]=  completo[\"gestion.fechaControl\"].str.split(\" \", n = 1, expand = True)[0]\n",
    "    completo[\"gestion.hora\"]=completo[\"gestion.fechaControl\"].str.split(\" \", n=1, expand=True)[1].str.split(\":\", n = 2, expand = True)[0]\n",
    "    completo[\"gestion.minuto\"]=completo[\"gestion.fechaControl\"].str.split(\" \", n=1, expand=True)[1].str.split(\":\", n = 2, expand = True)[1]\n",
    "    completo[\"gestion.anyo\"] =  completo[\"gestion.fecha\"].str[0:4]\n",
    "    completo[\"gestion.mes\"]  =  completo[\"gestion.fecha\"].str[5:7]\n",
    "    completo[\"gestion.dia\"]  =  completo[\"gestion.fecha\"].str[8:10]\n",
    "    completo[\"gestion.totales.cantDev\"]  = totales  \n",
    "    completo[\"gestion.totales.cantDevConectados\"]  =  conectados\n",
    "    completo[\"gestion.totales.cantDevdesConectados\"]  =  desconectados\n",
    "    \n",
    "    print(completo)\n",
    "except Exception as e:\n",
    "    completo = pd.DataFrame(columns=['gestion.estado.nombreSede', 'gestion.estado.DDA','gestion.estado.estadoInstalacion', 'gestion.estado.COD_ISO',\n",
    "   'gestion.estado.energia', 'gestion.estado.dptoGestion','gestion.estado.codCentroPoblado', 'gestion.estado.codDanesede',\n",
    "   'gestion.estado.tipoSitio', 'gestion.estado.codDaneMuni','gestion.estado.nombre_centro_pob', 'gestion.estado.site_id',\n",
    "   'gestion.estado.matricula', 'gestion.estado.energiadesc','gestion.estado.grupoDesc', 'gestion.estado.cod_servicio',\n",
    "   'gestion.estado.region', 'gestion.estado.detalleSitio','gestion.estado.muniGestion', 'gestion.estado.id_Beneficiario',\n",
    "   'gestion.estado.codDaneInstitucionEdu', 'gestion.estado.location','status', 'gestion.estadoCentro', 'itsm_incident_id', 'fechahora',\n",
    "   'gestion.fechaControl', 'gestion.fecha', 'gestion.hora', 'gestion.anyo','gestion.mes', 'gestion.dia', 'gestion.totales.cantDev',\n",
    "   'gestion.totales.cantDevConectados','gestion.totales.cantDevdesConectados'])\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispo.rename(columns={'site_id':'gestion.estado.site_id',\n",
    "                         'disponibilidad' : 'gestion.estado.disponibilidad',\n",
    "                         'max_fecha':'gestion.estado.max_fecha'},\n",
    "                inplace=True)\n",
    "\n",
    "idx=completo[completo['gestion.estado.matricula']=='No aplica'].index\n",
    "\n",
    "completo.loc[idx,'gestion.estado.matricula']=0\n",
    "\n",
    "print(df_dispo.columns)\n",
    "completo = pd.merge(completo, df_dispo,on=['gestion.estado.site_id','mac'],how='inner')\n",
    "print(completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completo)\n",
    "if not completo.empty:\n",
    "    completo[\"gestion.fechaControl\"] =  completo['gestion.estado.max_fecha']\n",
    "    completo[\"gestion.fecha\"]=  completo[\"gestion.fechaControl\"].str.split(\" \", n = 1, expand = True)[0]\n",
    "    completo[\"gestion.hora\"]=completo[\"gestion.fechaControl\"].str.split(\" \", n=1, expand=True)[1].str.split(\":\", n = 2, expand = True)[0]\n",
    "    completo[\"gestion.minuto\"]=completo[\"gestion.fechaControl\"].str.split(\" \", n=1, expand=True)[1].str.split(\":\", n = 2, expand = True)[1]\n",
    "    completo[\"gestion.anyo\"] =  completo[\"gestion.fecha\"].str[0:4]\n",
    "    completo[\"gestion.mes\"]  =  completo[\"gestion.fecha\"].str[5:7]\n",
    "    completo[\"gestion.dia\"]  =  completo[\"gestion.fecha\"].str[8:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insertando los datos en el indice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_these_keys = ['gestion.estado.id_Beneficiario'\n",
    "                  ,'gestion.estadoCentro'\n",
    "                  ,'gestion.estado.nombreSede'\n",
    "                  ,'gestion.estado.COD_ISO'\n",
    "                  ,'gestion.estado.codDanesede'\n",
    "                  ,'gestion.estado.nombre_centro_pob'\n",
    "                  ,'gestion.estado.site_id'\n",
    "                  ,'gestion.estado.dptoGestion'\n",
    "                  ,'gestion.estado.energiadesc'\n",
    "                  ,'gestion.estado.muniGestion'\n",
    "                  ,'gestion.estado.location'  \n",
    "                  ,'gestion.estado.DDA'\n",
    "                  ,'gestion.estado.nombreInstitucionEd'\n",
    "                  ,'gestion.estado.matricula'\n",
    "                  ,'gestion.estado.municipioPDET'    \n",
    "                  ,'gestion.fechaControl'\n",
    "                  ,'gestion.fecha'\n",
    "                  ,'gestion.anyo'\n",
    "                  ,'gestion.mes'\n",
    "                  ,'gestion.dia'\n",
    "                  ,'gestion.hora'\n",
    "                  ,'gestion.totales.cantDev'\n",
    "                  ,'gestion.totales.cantDevConectados'\n",
    "                  ,'gestion.totales.cantDevdesConectados'\n",
    "                  ,'gestion.estado.disponibilidad'\n",
    "                  ,'gestion.estado.max_fecha'\n",
    "                  ,'gestion.estado.cod_servicio'\n",
    "                  ,'gestion.estado.codDaneMuni'                  \n",
    "                  ,'gestion.estado.codCentroPoblado'\n",
    "                  ,'gestion.estado.codDaneInstitucionEdu'\n",
    "                  ,'gestion.estado.tipoSitio'\n",
    "                  ,'gestion.estado.detalleSitio'\n",
    "                  ,'gestion.estado.energia'\n",
    "                  ,'gestion.estado.region'\n",
    "                  ,'gestion.estado.grupoDesc'\n",
    "                  ,'gestion.estado.estadoInstalacion'\n",
    "                  ,'@timestamp'\n",
    "                  ,'mac'\n",
    "                  ,'ip'\n",
    "                  ,'ap_group'\n",
    "                  ,'status.macRed'\n",
    "                  ,'gestion.minuto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo['@timestamp'] = now.isoformat()\n",
    "def doc_generator2(df,use_these_keys):\n",
    "    df_iter = df.iterrows()\n",
    "    for index, document in df_iter:\n",
    "        yield {\n",
    "                \"_index\": indice, \n",
    "#                 \"_id\": f\"{'Estado-'+str(+document['gestion.estado.id_Beneficiario']) + '-' + str(document['gestion.fechaControl'])}\",\n",
    "                \"_id\": f\"{str(document['mac'])}\",\n",
    "                \"_source\": filterKeys(document,use_these_keys),\n",
    "            }\n",
    "\n",
    "salida = helpers.bulk(es, doc_generator2(completo,use_these_keys))\n",
    "print(completo)\n",
    "print(\"Fecha: \", now,\"- Llamadas insertadas en indice principal:\",salida[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualizando fecha de control de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_ejecucion = (datetime.strptime(fecha_ejecucion, \"%Y-%m-%d\"'T'\"%H:%M:%S\")+timedelta(minutes=60)).strftime(\"%Y-%m-%d\"'T'\"%H:%M:%S\")[0:15] + '0:00'    \n",
    "\n",
    "if fecha_ejecucion > str(now.strftime(\"%Y-%m-%d\"'T'\"%H:%M:%S\"))[0:15] + '0:00':\n",
    "    fecha_ejecucion = str(now.strftime(\"%Y-%m-%d\"'T'\"%H:%M:%S\"))[0:15] + '0:00'\n",
    "\n",
    "response = es.index(\n",
    "        index = indice_control,\n",
    "        id = 'jerarquia_disponibilidad1',\n",
    "        body = { 'jerarquia_disponibilidad1': 'jerarquia_disponibilidad1','gestion.fechaControl' : fecha_ejecucion}\n",
    ")\n",
    "print(\"actualizada fecha control de ejecucion:\",fecha_ejecucion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_end = perf_counter()\n",
    "print(f'TOTAL {total_end - total_start} seconds.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
