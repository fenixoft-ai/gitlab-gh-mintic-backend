{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Que hace este script?\n",
    "* Calcula para cada site id: trafico.totales.promedioIN, trafico.totales.promedioOUT, trafico.totales.promedioConsumo\n",
    "\n",
    "Valores calculado para hora de los ultimos 10 días"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from ssl import create_default_context\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import parametros\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectando a ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ultima línea se utiliza para garantizar la ejecución de la consulta\n",
    "* timeout es el tiempo para cada ejecución\n",
    "* max_retries el número de intentos si la conexión falla\n",
    "* retry_on_timeout para activar los reitentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = create_default_context(cafile=parametros.cafile)\n",
    "es = Elasticsearch(\n",
    "    parametros.servidor,\n",
    "    http_auth=(parametros.usuario_EC, parametros.password_EC),\n",
    "    scheme=\"https\",\n",
    "    port=parametros.puerto,\n",
    "    ssl_context=context,\n",
    "    timeout=60, max_retries=3, retry_on_timeout=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando fechas para la ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se calculan las fechas para asociar al nombre del indice\n",
    "* fecha_hoy es usada para concatenar al nombre del indice principal previa inserción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "fecha_hoy = str(now.strftime(\"%Y.%m.%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiendo indice principal con fecha de hoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos valores se deben ajustar según ambiente. No es automático ya que no hay separación de ambientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = parametros.mintic_concat_index\n",
    "indice_control = parametros.mintic_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para generar JSON compatible con ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterKeys(document):\n",
    "    return {key: document[key] for key in use_these_keys }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leyendo indice semilla-inventario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el script que ingesta semilla, trae la información de los centros de conexión administrados. Para el indice principal se requiere:\n",
    "\n",
    "* site_id como llave del centro de conexión.\n",
    "* Datos geográficos (Departamento, municipio, centro poblado, sede, energía, latitud, longitud, COD_ISO, entre otros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 10000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= parametros.semilla_inventario_index,\n",
    "        body={\n",
    "               \"_source\": ['site_id','nombre_municipio', 'nombre_departamento', 'nombre_centro_pob', 'nombreSede' \n",
    "                           , 'energiadesc', 'latitud', 'longitud','COD_ISO','id_Beneficiario']\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "\n",
    "    datos_semilla = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\n",
    "except:\n",
    "    print(\"fecha:\",now,\"- Error en lectura de datos semilla\")\n",
    "    #exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se valida latitud y longitud. \n",
    "* Se calcula location\n",
    "* Se renombren campos de semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(x):\n",
    "    patron = re.compile('^(\\-?\\d+(\\.\\d+)?),\\s*(\\-?\\d+(\\.\\d+)?)$') #patrón que debe cumplir\n",
    "    if (not patron.match(x) is None):\n",
    "        return x.replace(',','.')\n",
    "    else:\n",
    "        #Código a ejecutar si las coordenadas no son válidas\n",
    "        return 'a'\n",
    "datos_semilla['latitud'] = datos_semilla['latitud'].apply(get_location)\n",
    "datos_semilla['longitud'] = datos_semilla['longitud'].apply(get_location)\n",
    "datos_semilla['trafico.location'] = datos_semilla['latitud'] + ',' + datos_semilla['longitud']\n",
    "datos_semilla['trafico.location']=datos_semilla['trafico.location'].str.replace('a,a','')\n",
    "datos_semilla.drop(columns=['latitud','longitud'],inplace=True)\n",
    "\n",
    "datos_semilla = datos_semilla.rename(columns={'nombre_municipio': 'trafico.nombreMunicipio'\n",
    "                                              , 'nombre_departamento' : 'trafico.nombreDepartamento'\n",
    "                                              , 'nombre_centro_pob': 'trafico.localidad'\n",
    "                                              , 'nombreSede' : 'trafico.nomCentroDigital'\n",
    "                                              , 'energiadesc' : 'trafico.sistemaEnergia'\n",
    "                                              , 'COD_ISO' : 'trafico.codISO'\n",
    "                                              , 'id_Beneficiario' : 'trafico.idBeneficiario'})\n",
    "datos_semilla.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leyendo indice cambium-devicedevices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lee la información de los dispositivos de red monitoreados por Cambium. En esta lectura no hay referencia de fechas ya que solo hay una ocurrencia por MAC de dispositivo de red.\n",
    "\n",
    "* site_id es la llave para cruzar con cada centro de conexión.\n",
    "* mac, IP y name son datos básicos del dispositivo.\n",
    "* ap_group identifica los dispositivos como INDOOR u OUTDOOR\n",
    "* status indica el estado del dispositivo en el momento de la lectura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 30000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= parametros.cambium_d_d_index,\n",
    "        body={\n",
    "                    \"_source\": [\"site_id\",\"mac\",\"ap_group\"]  \n",
    "                  , \"query\": {\n",
    "                    \"match_all\": {}\n",
    "                  }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "\n",
    "    datos_dev = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\n",
    "except:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se descartan registros con site_id vacios y se limpian los NaN del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev.dropna(subset=['site_id'])\n",
    "datos_dev.fillna('', inplace=True)\n",
    "datos_dev = datos_dev.drop(datos_dev[(datos_dev['site_id']=='')].index)\n",
    "datos_dev.sort_values(['site_id','ap_group'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se limpian datos mal formados de ap_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev['ap_group'] = datos_dev['ap_group'].str.split(\"-\", n = 1, expand = True)[0]\n",
    "datos_dev['ap_group'] = datos_dev['ap_group'].str.split(\"_\", n = 1, expand = True)[0]\n",
    "datos_dev = datos_dev.drop(datos_dev[(datos_dev['ap_group']=='')].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se borran duplicados por MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev = datos_dev.drop_duplicates('mac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se renombran campos según estructura de indice final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_dev = datos_dev.rename(columns={'ap_mac' : 'trafico.macRed','ap_group': 'trafico.apGroup'\n",
    "                                        , 'mac' : 'trafico.macRed'\n",
    "                                        , 'status' : 'trafico.status.macRed'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trae la ultima fecha para control de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando en el rango de tiempo de la ejecución, no se insertan nuevos valores, las fecha maxima en indice mintic no aumenta, por tanto se usa esta fecha de control para garantizar que incremente el bucle de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultima fecha para control de ejecucion: 2021-06-04 01:00:00\n"
     ]
    }
   ],
   "source": [
    "total_docs = 1\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= indice_control,\n",
    "        body={\n",
    "               \"_source\": [\"trafico.fechaControl\"],\n",
    "              \"query\": {\n",
    "                \"bool\": {\n",
    "                  \"filter\": [\n",
    "                  {\n",
    "                    \"exists\": {\n",
    "                      \"field\":\"jerarquia_trafico_promedios\"\n",
    "                    }\n",
    "                  }\n",
    "                  ]\n",
    "                }\n",
    "              }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        fecha_ejecucion = doc[\"_source\"]['trafico.fechaControl']\n",
    "except:\n",
    "    fecha_ejecucion = '2021-05-01 00:00:00'\n",
    "if response[\"hits\"][\"hits\"] == []:\n",
    "    fecha_ejecucion = '2021-05-01 00:00:00'\n",
    "print(\"ultima fecha para control de ejecucion:\",fecha_ejecucion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se lee la información de cambium device performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Se toma los valores de dispositivos y su desempeño.\n",
    " * mac del dispositivo de red\n",
    " * timestamp es la fecha y hora de la medición\n",
    " * radio.* volumen de datos descargados(r) y cargados(t)\n",
    " \n",
    " Se usa un rango de fechas para calcular promedio y la hora sobre la cual se calculará"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traePerformance(hora,fecha_ini,fecha_tope):\n",
    "    total_docs = 5000000\n",
    "    response = es.search(\n",
    "        index= parametros.cambium_d_p_index,\n",
    "        body={\n",
    "                \"_source\": [\"mac\",\"timestamp\",\"radio.5ghz.rx_bps\",\n",
    "                           \"radio.5ghz.tx_bps\",\"radio.24ghz.rx_bps\"\n",
    "                          ,\"radio.24ghz.tx_bps\"]\n",
    "              , \"query\": {\n",
    "                    \"bool\": {\n",
    "                      \"must\": [\n",
    "                        {\n",
    "                          \"script\": {\n",
    "                            \"script\": {\n",
    "                               \"source\": \"doc['timestamp'].value.hour == params.startHour\",\n",
    "                               \"params\": {\n",
    "                                 \"startHour\": hora\n",
    "                               }\n",
    "                            }\n",
    "                          }\n",
    "                        },\n",
    "                        {\n",
    "                          \"range\": {\n",
    "                            \"timestamp\": {\n",
    "                                \"gte\": fecha_ini,\n",
    "                                #\"gte\": \"2021-05-01 00:00:00\",\n",
    "                                \"lt\": fecha_tope\n",
    "                            }\n",
    "                          }\n",
    "                        }  \n",
    "                      ]\n",
    "                    }\n",
    "                }\n",
    "        },\n",
    "        size=total_docs\n",
    "    )\n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "\n",
    "    return pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanzando primera ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se calcula rango de fechas a procesar. Para este script la muetras sobre la cual se hace el promedio es de los últimos 7 días.\n",
    "* Se realiza consulta.\n",
    "* Si no existen datos, se incrementa el rango de fecha y se consulta nuevamente. \n",
    "* Se repite el proceso hasta que se consiguen datos o hasta que se alcance la fecha actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_max_mintic = fecha_ejecucion\n",
    "fecha_tope_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(hours=1)-timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "fecha_ini = (datetime.strptime(fecha_tope_mintic, '%Y-%m-%d %H:%M:%S')-timedelta(days=7)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "if fecha_ini[0:10] < '2021-05-01':\n",
    "    fecha_ini = '2021-05-01 00:00:00'\n",
    "\n",
    "datos_performance = traePerformance(int(fecha_max_mintic[11:13]),fecha_ini,fecha_tope_mintic)\n",
    "\n",
    "if datos_performance is None or datos_performance.empty:\n",
    "    while (datos_performance is None or datos_performance.empty) and ((datetime.strptime(fecha_max_mintic[0:10], '%Y-%m-%d').strftime(\"%Y-%m-%d %H:%M:%S\")) < str(now.strftime(\"%Y-%m-%d %H:%M:%S\"))):\n",
    "        fecha_max_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(hours=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_tope_mintic = (datetime.strptime(fecha_tope_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(hours=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        fecha_ini = (datetime.strptime(fecha_ini, '%Y-%m-%d %H:%M:%S')+timedelta(hours=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        datos_performance = traePerformance(int(fecha_max_mintic[11:13]),fecha_ini,fecha_tope_mintic)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insertando promedios a indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_these_keys = ['trafico.nomCentroDigital',\n",
    "                  'trafico.codISO',\n",
    "                  'trafico.localidad',\n",
    "                  'trafico.siteID',\n",
    "                  'trafico.nombreDepartamento',\n",
    "                  'trafico.sistemaEnergia',\n",
    "                  'trafico.nombreMunicipio',\n",
    "                  'trafico.idBeneficiario',\n",
    "                  'trafico.totales.fechaControl',\n",
    "                  'trafico.totales.fecha',\n",
    "                  'trafico.totales.anyo',\n",
    "                  'trafico.totales.mes',\n",
    "                  'trafico.totales.dia',\n",
    "                  'trafico.totales.hora',\n",
    "                  'trafico.totales.promedioIN',\n",
    "                  'trafico.totales.promedioOUT',\n",
    "                  'trafico.totales.promedioConsumo',\n",
    "                    'nombreDepartamento',\n",
    "                    'nombreMunicipio',\n",
    "                    'idBeneficiario',\n",
    "                    'fecha',\n",
    "                    'anyo',\n",
    "                    'mes',\n",
    "                    'dia',\n",
    "                  '@timestamp']\n",
    "def doc_generator(df):\n",
    "    df_iter = df.iterrows()\n",
    "    for index, document in df_iter:\n",
    "        yield {\n",
    "                \"_index\": indice, \n",
    "                \"_id\": f\"{'PromedioTra-' + document['trafico.siteID'] + '-' +document['trafico.totales.fechaControl']}\",\n",
    "                \"_source\": filterKeys(document),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo de indicadores de consumos\n",
    "* Se hace promedio por sitio y fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha:  2021-06-10 15:34:29.113392 - Datos Trafico promedios en indice principal: 117\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    datos_performance.drop_duplicates(inplace=True)\n",
    "    datos_performance.rename(columns={'mac': 'trafico.macRed'}, inplace=True)\n",
    "    datos_performance = pd.merge(datos_performance, datos_dev, on='trafico.macRed',how='inner')\n",
    "    datos_performance.replace('','0',inplace=True)\n",
    "    datos_performance.fillna({'radio.5ghz.rx_bps':0,\n",
    "                      'radio.5ghz.tx_bps':0,\n",
    "                      'radio.24ghz.rx_bps':0,\n",
    "                      'radio.24ghz.tx_bps':0  \n",
    "                      },inplace=True)\n",
    "    datos_performance[['radio.5ghz.rx_bps','radio.5ghz.tx_bps','radio.24ghz.rx_bps','radio.24ghz.tx_bps']] = datos_performance[['radio.5ghz.rx_bps','radio.5ghz.tx_bps','radio.24ghz.rx_bps','radio.24ghz.tx_bps']].astype(float)\n",
    "    datos_performance['trafico.totales.traficoIN_aux'] = datos_performance['radio.5ghz.rx_bps'] + datos_performance['radio.24ghz.rx_bps']\n",
    "    datos_performance['trafico.totales.traficoOUT_aux'] = datos_performance['radio.5ghz.tx_bps'] + datos_performance['radio.24ghz.tx_bps']\n",
    "    aux_performance=datos_performance[['site_id'\n",
    "                      , 'trafico.totales.traficoIN_aux'\n",
    "                      ,'trafico.totales.traficoOUT_aux']].groupby(['site_id']).agg(['mean']).reset_index()\n",
    "    aux_performance.columns = aux_performance.columns.droplevel(1)\n",
    "    aux_performance['trafico.totales.promedioIN'] = round((aux_performance['trafico.totales.traficoIN_aux']/float(1<<30)),6)\n",
    "    aux_performance['trafico.totales.promedioOUT'] = round((aux_performance['trafico.totales.traficoOUT_aux']/float(1<<30)),6)\n",
    "    aux_performance['trafico.totales.promedioConsumo'] = aux_performance['trafico.totales.promedioIN'] + aux_performance['trafico.totales.promedioOUT']\n",
    "    #Se totaliza para la sede completa\n",
    "    aux_performance['trafico.totales.promedioConsumo'] = round(aux_performance['trafico.totales.promedioConsumo'],6)\n",
    "\n",
    "    ### Generando columnas con fecha, anyo, mes, dia, hora y minuto por separado\n",
    "    aux_performance[\"trafico.totales.fechaControl\"] = fecha_max_mintic\n",
    "    aux_performance[\"trafico.totales.fecha\"] = fecha_max_mintic.split(\" \")[0]\n",
    "    aux_performance[\"trafico.totales.hora\"] = fecha_max_mintic.split(\" \")[1].split(\":\")[0]\n",
    "    aux_performance[\"trafico.totales.anyo\"] = fecha_max_mintic[0:4]\n",
    "    aux_performance[\"trafico.totales.mes\"] = fecha_max_mintic[5:7]\n",
    "    aux_performance[\"trafico.totales.dia\"] = fecha_max_mintic[8:10]\n",
    "    ### Renombrado de campos\n",
    "\n",
    "    ##nulos a cero\n",
    "    aux_performance.fillna({'trafico.totales.promedioConsumo':0,\n",
    "                      'trafico.totales.promedioIN':0,\n",
    "                      'trafico.totales.promedioOUT':0\n",
    "                      },inplace=True)\n",
    "    aux_performance[['trafico.totales.promedioConsumo','trafico.totales.promedioIN','trafico.totales.promedioOUT']] = aux_performance[['trafico.totales.promedioConsumo','trafico.totales.promedioIN','trafico.totales.promedioOUT']].astype(float)\n",
    "    mintic_02 = pd.merge(datos_semilla,  aux_performance, on='site_id',how='inner')\n",
    "    mintic_02.rename(columns={'site_id': 'trafico.siteID'}, inplace=True)\n",
    "    mintic_02['@timestamp'] = now.isoformat()\n",
    "    mintic_02['nombreDepartamento'] = mintic_02['trafico.nombreDepartamento']\n",
    "    mintic_02['nombreMunicipio'] = mintic_02['trafico.nombreMunicipio']\n",
    "    mintic_02['idBeneficiario'] = mintic_02['trafico.idBeneficiario']\n",
    "    mintic_02['fecha'] = mintic_02['trafico.totales.fecha']\n",
    "    mintic_02['anyo'] = mintic_02['trafico.totales.anyo']\n",
    "    mintic_02['mes'] = mintic_02['trafico.totales.mes']\n",
    "    mintic_02['dia'] = mintic_02['trafico.totales.dia']\n",
    "    salida = helpers.bulk(es, doc_generator(mintic_02))\n",
    "    print(\"Fecha: \", now,\"- Datos Trafico promedios en indice principal:\",salida[0])\n",
    "except:\n",
    "    print(\"Fecha: \", now,\"- No se insertaron datos de promedios en indice principal\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando fecha para control de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se actualiza la fecha de control. Si el calculo supera la fecha hora actual, se asocia esta ultima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_ejecucion = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(hours=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "if fecha_ejecucion > str(now.strftime('%Y-%m-%d %H:%M:%S'))[0:14] + '00:00':\n",
    "    fecha_ejecucion = str(now.strftime('%Y-%m-%d %H:%M:%S'))[0:14] + '00:00'\n",
    "response = es.index(\n",
    "        index = indice_control,\n",
    "        id = 'jerarquia_trafico_promedios',\n",
    "        body = { 'jerarquia_trafico_promedios': 'trafico_promedios','trafico.fechaControl' : fecha_ejecucion}\n",
    ")\n",
    "print(\"actualizada fecha control de ejecucion:\",fecha_ejecucion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
