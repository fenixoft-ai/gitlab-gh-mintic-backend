{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from ssl import create_default_context\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "#from getpass import getpass\n",
    "import parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leyendo datos del indice cambium-devices-performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = create_default_context(cafile=parametros.cafile)\n",
    "es = Elasticsearch(\n",
    "    parametros.servidor,\n",
    "    http_auth=(parametros.usuario_EC, parametros.password_EC),\n",
    "    scheme=\"https\",\n",
    "    port=parametros.puerto,\n",
    "    ssl_context=context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tomando fecha mas reciente del indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "new_date = now - timedelta(days=3)\n",
    "ayer = now - timedelta(days=1)\n",
    "fecha_hoy = str(now.strftime(\"%Y.%m.%d\"))\n",
    "ahora_cdd = str(now.strftime(\"%Y-%m-%d\"' '\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahora_cdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = 0\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= parametros.cambium_d_p_index,\n",
    "        body={\"aggs\" : {\n",
    "                   \"max_date\": {\"max\": {\"field\": \"timestamp\", \"format\": \"yyyy-MM-dd HH:mm:ss\"}}\n",
    "                }\n",
    "             },\n",
    "        size=total_docs\n",
    "    )\n",
    "    #print(es.info())\n",
    "    elastic_docs = response[\"aggregations\"]\n",
    "    fecha_max=response[\"aggregations\"][\"max_date\"]['value_as_string']\n",
    "except:\n",
    "    fecha_max = (new_date).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"Fecha maxima en indice:\",fecha_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date_f = datetime.strptime(fecha_max, '%Y-%m-%d  %H:%M:%S')\n",
    "aaa = str(new_date_f.strftime(\"%Y%m%d%H%M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aa = str(now.strftime(\"%Y%m%d%H\"))+'00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_ini = (datetime.strptime(aaa, '%Y%m%d%H%M')-timedelta(minutes=0)).strftime(\"%Y%m%d%H%M\")\n",
    "fecha_fin = (datetime.strptime(fecha_ini, '%Y%m%d%H%M')+timedelta(minutes=360)).strftime(\"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[6]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "echa_ini = \"20210730000\"<br>\n",
    "echa_fin = \"202107302359\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[7]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sacar las MAC de devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "def traerDDevices(fecha_max,fecha_tope):<br>\n",
    "    total_docs = 10000<br>\n",
    "    try:<br>\n",
    "        response = es.search(<br>\n",
    "            index= parametros.cambium_d_d_index,<br>\n",
    "            body={<br>\n",
    "                \"_source\": [\"registration_date\",\"mac\",\"ip\",\"ap_group\",\"site_id\",\"status\"]<br>\n",
    "                ,\"query\":{<br>\n",
    "                    \"bool\": {<br>\n",
    "                      \"filter\": [<br>\n",
    "                        {<br>\n",
    "                          \"range\": {<br>\n",
    "                            \"registration_date\": {<br>\n",
    "                              \"gte\": fecha_max,<br>\n",
    "                              \"lt\": fecha_tope<br>\n",
    "                            }<br>\n",
    "                          }<br>\n",
    "                        }<br>\n",
    "                      ],<br>\n",
    "                    }<br>\n",
    "                }<br>\n",
    "            },<br>\n",
    "            size=total_docs<br>\n",
    "        )<br>\n",
    "        elastic_docs = response[\"hits\"][\"hits\"]<br>\n",
    "        fields = {}<br>\n",
    "        for num, doc in enumerate(elastic_docs):<br>\n",
    "            source_data = doc[\"_source\"]<br>\n",
    "            for key, val in source_data.items():<br>\n",
    "                try:<br>\n",
    "                    fields[key] = np.append(fields[key], val)<br>\n",
    "                except KeyError:<br>\n",
    "                    fields[key] = np.array([val])<br>\n",
    "        datos_DDevices  = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ]))<br>\n",
    "        datos_DDevices  = datos_DDevices.rename(columns={'ap_group':'gestion.ptos_acceso'})<br>\n",
    "        datos_DDevices  = datos_DDevices.dropna(subset=['site_id'])<br>\n",
    "        return datos_DDevices <br>\n",
    "    except:<br>\n",
    "        return pd.DataFrame()<br>\n",
    "    <br>\n",
    "fec1=\"2021-04-01 00:00:00\"<br>\n",
    "datos_mac  = traerDDevices(fec1 , ahora_cdd)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = parametros.cambium_d_d_index # + '-' + fecha_hoy\n",
    "total_docs = 10000\n",
    "try:\n",
    "    response = es.search(\n",
    "        index= indice, \n",
    "        body={\n",
    "               \"_source\": ['*']\n",
    "        },\n",
    "        size=total_docs\n",
    "    )    \n",
    "    elastic_docs = response[\"hits\"][\"hits\"]\n",
    "    fields = {}\n",
    "    for num, doc in enumerate(elastic_docs):\n",
    "        source_data = doc[\"_source\"]\n",
    "        for key, val in source_data.items():\n",
    "            try:\n",
    "                fields[key] = np.append(fields[key], val)\n",
    "            except KeyError:\n",
    "                fields[key] = np.array([val])\n",
    "    datos_mac = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\n",
    "except:\n",
    "    print(\"fecha:\",now,\"- Error en lectura de datos_mac: \", parametros.cambium_d_d_index, \" servidor: \", parametros.servidor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datos_mac is None or datos_mac.empty:\n",
    "    print (\" No se sacaron datos de Cambium-DeviceDevices. por lo que el proceso no continua. \", now, parametros.cambium_d_d_index)       \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_mac = datos_mac[[\"mac\",\"site_id\"]].groupby([\"mac\"]).agg(['count']).reset_index()\n",
    "datos_mac.columns = datos_mac.columns.droplevel(1)  \n",
    "datos_mac =datos_mac.dropna(subset=['mac'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atos_mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atos_mac[\"mac\"].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leyendo la APi cambium-devices-performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[8]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la cabecera y el diccionario con los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arranca = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atos_api = pd.DataFrame(columns=[\"name\",\"network\",\"type\",\"timestamp\",\"radio\",\"tower\",\"mac\",\"mode\"<br>\n",
    "                                                     ,\"sm_drops\",\"managed_account\",\"online_duration\",\"uptime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_api = pd.DataFrame()\n",
    "#url_cambium2 = [\"http://100.123.26.252/api/v2/\",\"http://100.123.26.224/api/v2/\"]\n",
    "mac =\"BC:E6:7C:5F:07:11\"\n",
    "for i in datos_mac.index: \n",
    "    mac = datos_mac[\"mac\"][i]         \n",
    "    for k in range(0,len(parametros.url_cambium)):\n",
    "        token_aux = 'Bearer ' + parametros.cambium_token_aux[k]\n",
    "        cabecera1 = { 'Content-Type': 'application/json', 'Authorization' : token_aux, 'accept' : '*/*' } \n",
    "        url = parametros.url_cambium[k] + \"devices/\"+mac+\"/performance\" + '?start_time='+ fecha_ini + '&stop_time=' + fecha_fin    \n",
    "        try:\n",
    "             r = requests.get(url, headers = cabecera1, verify=False)\n",
    "        except KeyError:\n",
    "            print (\"Error URL, \", url, \" tipo: \", KeyError)\n",
    "            r.status_code = 400\n",
    "        #print(\" url: \", url)\n",
    "        #print(\" code: \" , r.status_code)\n",
    "        #break    \n",
    "        if r.status_code == 200:\n",
    "            res = json.loads(r.text)\n",
    "            dato_param = res['paging']        \n",
    "            #se calcula los ciclos de la consulta paginada\n",
    "            ciclos = int(round(dato_param['total']/100,0))\n",
    "            #print(res['paging'])\n",
    "            if dato_param['total']>0:\n",
    "                 ciclos = ciclos + 1\n",
    "            print(\" dato_param['total'] \", dato_param['total'], ciclos)\n",
    "            i = 0\n",
    "            while i < ciclos:                \n",
    "                offset = str(i*100)  # aqui modifique deberia de comenzar en 1 y luego de 100 en 100 GM\n",
    "                url2 = parametros.url_cambium[k] + \"devices/\"+mac+\"/performance\" + '?offset=' + offset  + '&start_time=' + fecha_ini + '&stop_time=' + fecha_fin \n",
    "                i+=1\n",
    "                print(url2)\n",
    "                try:         \n",
    "                    r = requests.get(url2, headers = cabecera1, verify=False)            \n",
    "                except KeyError:\n",
    "                    print (\"Error URL, \", url, \" tipo: \", KeyError)\n",
    "                    r.status_code = 400\n",
    "                \n",
    "                if r.status_code == 200:\n",
    "                    #print(\"respuesta a200: \",r.text)\n",
    "                    res = json.loads(r.text)\n",
    "                    #print(\"respuesta a200  - res['data'] = \",res['data'])    \n",
    "                    datos_api = datos_api.append(res['data'], ignore_index=True)\n",
    "                    #print(res['paging'])\n",
    "                else:\n",
    "                    print(\"2.-Fecha:\",now,\"- Error bucle interno: \",r.status_code , \" no trajo datos: \", url2)\n",
    "                    break                \n",
    "        else:\n",
    "            print(\"1.-Fecha:\",now,\"- Error bucle externo: \",r.status_code, \" no trajo datos: \", url)\n",
    "            break\n",
    "        \n",
    "termina = datetime.now()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fin tiempos 1.-a:\",arranca,\"- termina: \",termina)\n",
    "#datos_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rint (datos_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se descompone el diccionario radio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ry:<br>\n",
    "   datos_api['radio.dl_kbits'] = datos_api.loc[:, 'radio'].apply(lambda x: x['dl_kbits'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.dl_kbits'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.dl_mcs'] = datos_api.loc[:, 'radio'].apply(lambda x: x['dl_mcs'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.dl_mcs'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.dl_pkts'] = datos_api.loc[:, 'radio'].apply(lambda x: x['dl_pkts'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.dl_pkts'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.dl_rssi'] = datos_api.loc[:, 'radio'].apply(lambda x: x['dl_rssi'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.dl_rssi'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.dl_snr'] = datos_api.loc[:, 'radio'].apply(lambda x: x['dl_snr'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.dl_snr'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.dl_throughput'] = datos_api.loc[:, 'radio'].apply(lambda x: x['dl_throughput'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.dl_throughput'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.ul_kbits'] = datos_api.loc[:, 'radio'].apply(lambda x: x['ul_kbits'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.ul_kbits'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.ul_mcs'] = datos_api.loc[:, 'radio'].apply(lambda x: x['ul_mcs'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.ul_mcs'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.ul_pkts'] = datos_api.loc[:, 'radio'].apply(lambda x: x['ul_pkts'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.ul_pkts'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.ul_retransmits_pct'] = datos_api.loc[:, 'radio'].apply(lambda x: x['ul_retransmits_pct'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.ul_retransmits_pct'] = ''<br>\n",
    "ry:<br>\n",
    "   datos_api['radio.ul_throughput'] = datos_api.loc[:, 'radio'].apply(lambda x: x['ul_throughput'])<br>\n",
    "xcept:<br>\n",
    "   datos_api['radio.ul_throughput'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[9]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " = pd.DataFrame(columns=[\"radio.5ghz.rx_bps\",\"radio.5ghz.tx_bps\"<br>\n",
    "                        ,\"radio.24ghz.rx_bps\",\"radio.24ghz.tx_bps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_api['tower'] = ''\n",
    "datos_api['sm_drops'] = ''\n",
    "datos_api['online_duration'] = 0\n",
    "datos_api['uptime'] = 0\n",
    "#datos_api['radio.dl_snr'] = ''\n",
    "#datos_api['radio.dl_throughput'] = ''\n",
    "#datos_api['radio.ul_kbits'] = ''\n",
    "#datos_api['radio.ul_mcs'] = ''\n",
    "#datos_api['radio.ul_pkts'] = ''\n",
    "#datos_api['radio.ul_rssi'] = ''\n",
    "#datos_api['radio.ul_snr'] = ''\n",
    "#datos_api['radio.5ghz.rx_bps'] = datos_api['radios'][1]\n",
    "#datos_api['radio.5ghz.tx_bps'] = datos_api['radios'][1]['tx_bps']\n",
    "#datos_api['radio.24ghz.rx_bps'] = datos_api['radios'][0]['rx_bps']\n",
    "#datos_api['radio.24ghz.tx_bps'] = datos_api['radios'][0]['tx_bps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_datos = datos_api.to_numpy()\n",
    "print (len(array_datos))\n",
    "list_datos = datos_api.T.to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in enumerate(list_datos):\n",
    "    if 'radios' in item.keys():\n",
    "    #if item.has_key('radios'):\n",
    "        if (isinstance(item['radios'], float) == False):\n",
    "            radios_arr = item['radios']\n",
    "            item['radio.dl_kbits'] = ''\n",
    "            item['radio.dl_mcs'] = ''\n",
    "            item['radio.dl_pkts'] = ''\n",
    "            item['radio.dl_rssi'] = ''\n",
    "            item['radio.dl_snr'] = ''\n",
    "            item['radio.dl_throughput'] = ''\n",
    "            item['radio.ul_kbits'] = ''\n",
    "            item['radio.ul_mcs'] = ''\n",
    "            item['radio.ul_pkts'] = ''\n",
    "            item['radio.ul_rssi'] = ''\n",
    "            item['radio.ul_snr'] = ''\n",
    "            item['radio.ul_retransmits_pct'] = ''\n",
    "            \n",
    "            if 'rx_bps' in radios_arr[1].keys():\n",
    "                item['radio.5ghz.rx_bps'] = radios_arr[1]['rx_bps']\n",
    "            else:\n",
    "                item['radio.5ghz.rx_bps'] = ''\n",
    "            \n",
    "            if 'tx_bps' in radios_arr[1].keys():\n",
    "                item['radio.5ghz.tx_bps'] = radios_arr[1]['tx_bps']\n",
    "            else:\n",
    "                item['radio.5ghz.tx_bps'] = ''\n",
    "            \n",
    "            if 'rx_bps' in radios_arr[0].keys():\n",
    "                item['radio.24ghz.rx_bps'] = radios_arr[0]['rx_bps']\n",
    "            else:\n",
    "                item['radio.24ghz.rx_bps'] = ''\n",
    "            \n",
    "            if 'tx_bps' in radios_arr[0].keys():\n",
    "                item['radio.24ghz.tx_bps'] = radios_arr[0]['tx_bps']\n",
    "            else:\n",
    "                item['radio.24ghz.tx_bps'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(list_datos))\n",
    "#print(list_datos)\n",
    "#lista_data = list(list_datos)\n",
    "datos_api = pd.DataFrame(list_datos)\n",
    "#print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,datos in datos_api.items():\n",
    "    try:\n",
    "        a = 0\n",
    "        #d.loc[index] = [datos['radio']['5ghz']['rx_bps'],datos['radio']['5ghz']['tx_bps']\n",
    "        #                ,datos['radio']['24ghz']['rx_bps'],datos['radio']['24ghz']['tx_bps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #datos_api.iloc[index]['radio.5ghz.rx_bps'] = datos['radio']['5ghz']['rx_bps']\n",
    "        #print(index,datos_api.iloc[index]['radio']['5ghz']['rx_bps'])#['5ghz']['rx_bps'],datos['5ghz']['tx_bps'])\n",
    "    except:\n",
    "        pass\n",
    "#datos_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[10]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atos_api.columns[(datos_api['radio.5ghz']!='')]<br>\n",
    "[~(d['radio.5ghz.rx_bps'].isnull())]<br>\n",
    "atos_api = datos_api.merge(d, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[11]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(datos_api) > 0:\n",
    "    datos_api.drop(columns=['radios'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[12]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datos_api<br>\n",
    "esto fue agregado de prueba para ver los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[13]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atos_api.drop_duplicates(inplace=True)<br>\n",
    "Esta linea la quite porque para eliminar registro hay que tener un campo unique-primarykey, por lo cual da error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descartando datos de la API que ya estÃ¡n en el indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[14]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    datos_api['timestamp'] = (datos_api[\"timestamp\"].str.split(\"T\", n = 2, expand = True)[0])+' '+(datos_api[\"timestamp\"].str.split(\"T\", n = 2, expand = True)[1]).str.split(\"-\", n = 1, expand = True)[0]\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[15]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_api = datos_api.drop(datos_api[(datos_api['timestamp']<= fecha_max)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[16]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_api.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[22]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atos_api.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiendo indice con fecha e insertando en ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[17]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = parametros.cambium_d_p_index #+'-'+ fecha_hoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[23]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_these_keys = ['name', 'network', 'type', 'tower', 'mac', 'mode', 'sm_drops',\n",
    "                   'managed_account', 'online_duration', 'uptime', 'site',\n",
    "                   'radio.dl_kbits', 'radio.dl_mcs', 'radio.dl_pkts', 'radio.dl_rssi',\n",
    "                   'radio.dl_snr', 'radio.dl_throughput', 'radio.ul_kbits', 'radio.ul_mcs',\n",
    "                   'radio.ul_pkts', 'radio.ul_retransmits_pct', \n",
    "                   'radio.5ghz.rx_bps', 'radio.5ghz.tx_bps', 'radio.24ghz.rx_bps',\n",
    "                   'radio.24ghz.tx_bps','timestamp','@timestamp']\n",
    "def filterKeys(document):\n",
    "    return {key: document[key] for key in use_these_keys }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now()\n",
    "datos_api['@timestamp'] = timestamp.isoformat()\n",
    "def doc_generator(df):\n",
    "    df_iter = df.iterrows()\n",
    "    for index, document in df_iter:\n",
    "        yield {\n",
    "                \"_index\": indice, \n",
    "                \"_source\": filterKeys(document),\n",
    "            }\n",
    "salida = helpers.bulk(es, doc_generator(datos_api))\n",
    "print(\"Fecha\",now,\"- Total documentos insertados:\",salida[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
