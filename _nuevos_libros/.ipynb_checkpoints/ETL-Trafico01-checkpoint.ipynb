{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n# coding: utf-8\n\n# Â¿Que hace este script?\n# * Calcula para cada dispositivo de red: trafico.totales.traficoIN, trafico.totales.traficoOUT', trafico.totales.consumoGB'.\n# * Calcula para cada site_id: trafico.totales.sitio.traficoIN, trafico.totales.sitio.traficoOUT, trafico.totales.sitio.consumoGB\n\n# In[742]:\n\n\nfrom elasticsearch import Elasticsearch, helpers\nfrom ssl import create_default_context\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport parametros\nimport random\nimport re\n\n\n# ## Conectando a ElasticSearch\n\n# La ultima lÃ­nea se utiliza para garantizar la ejecuciÃ³n de la consulta\n# * timeout es el tiempo para cada ejecuciÃ³n\n# * max_retries el nÃºmero de intentos si la conexiÃ³n falla\n# * retry_on_timeout para activar los reitentos\n\n# In[743]:\n\n\ncontext = create_default_context(cafile=parametros.cafile)\nes = Elasticsearch(\n    parametros.servidor,\n    http_auth=(parametros.usuario_EC, parametros.password_EC),\n    scheme=\"https\",\n    port=parametros.puerto,\n    ssl_context=context,\n    timeout=60, max_retries=3, retry_on_timeout=True\n) \n\n\n# ### Calculando fechas para la ejecuciÃ³n\n\n# * Se calculan las fechas para asociar al nombre del indice\n# * fecha_hoy es usada para concatenar al nombre del indice principal previa inserciÃ³n\n\n# In[744]:\n\n\nnow = datetime.now()\nfecha_hoy = str(now.strftime(\"%Y.%m.%d\"))\n\n\n# ### Definiendo indice principal con fecha de hoy\n\n# Estos valores se deben ajustar segÃºn ambiente. No es automÃ¡tico ya que no hay separaciÃ³n de ambientes\n\n# In[745]:\n\n\nindice = parametros.trafico_tableros_trafico_index\nindice_control = parametros.tableros_mintic_control\n\n\n# ### FunciÃ³n para generar JSON compatible con ES\n\n# In[746]:\n\n\ndef filterKeys(document):\n    return {key: document[key] for key in use_these_keys }\n\n\n# ### leyendo indice semilla-inventario\n\n# En el script que ingesta semilla, trae la informaciÃ³n de los centros de conexiÃ³n administrados. Para el indice principal se requiere:\n# \n# * site_id como llave del centro de conexiÃ³n.\n# * Datos geogrÃ¡ficos (Departamento, municipio, centro poblado, sede, energÃ­a, latitud, longitud, COD_ISO, entre otros).\n\n# In[747]:\n\n\ntotal_docs = 10000\ntry:\n    response = es.search(\n        index= parametros.semilla_inventario_index,\n        body={\n               \"_source\": ['site_id','nombre_municipio', 'nombre_departamento', 'nombre_centro_pob', 'nombreSede' \n                           , 'energiadesc', 'latitud', 'longitud','COD_ISO','id_Beneficiario']\n        },\n        size=total_docs\n    )\n    #print(es.info())\n    elastic_docs = response[\"hits\"][\"hits\"]\n    fields = {}\n    for num, doc in enumerate(elastic_docs):\n        source_data = doc[\"_source\"]\n        for key, val in source_data.items():\n            try:\n                fields[key] = np.append(fields[key], val)\n            except KeyError:\n                fields[key] = np.array([val])\n\n    datos_semilla = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\nexcept:\n    print(\"fecha:\",now,\"- Error en lectura de datos semilla\")\n    #exit()\n    \n\n\n# In[748]:\n\n\ndatos_semilla['site_id'] = datos_semilla['site_id'].str.strip()\n\n\n# Se valida latitud y longitud, se genera campo location y se renombran los campos de semilla\n\n# In[749]:\n\n\ndef get_location(x,y='lat'):\n    patron = re.compile('^(\\-?\\d+(\\.\\d+)?),\\s*(\\-?\\d+(\\.\\d+)?)$') #patrÃ³n que debe cumplir\n    if (not patron.match(x) is None) and (str(x)!=''):\n        return x.replace(',','.')\n    else:\n        #CÃ³digo a ejecutar si las coordenadas no son vÃ¡lidas\n        return '4.596389' if y=='lat' else '-74.074639'\n    \ndatos_semilla['latitud'] = datos_semilla['latitud'].apply(lambda x:get_location(x,'lat'))\ndatos_semilla['longitud'] = datos_semilla['longitud'].apply(lambda x:get_location(x,'lon'))\n\ndatos_semilla['trafico.location'] = datos_semilla['latitud'] + ',' + datos_semilla['longitud']\ndatos_semilla['trafico.location']=datos_semilla['trafico.location'].str.replace('a,a','')\ndatos_semilla.drop(columns=['latitud','longitud'],inplace=True)\n\ndatos_semilla = datos_semilla.rename(columns={'nombre_municipio': 'trafico.nombreMunicipio'\n                                              , 'nombre_departamento' : 'trafico.nombreDepartamento'\n                                              , 'nombre_centro_pob': 'trafico.localidad'\n                                              , 'nombreSede' : 'trafico.nomCentroDigital'\n                                              , 'energiadesc' : 'trafico.sistemaEnergia'\n                                              , 'COD_ISO' : 'trafico.codISO'\n                                              , 'id_Beneficiario' : 'trafico.idBeneficiario'})\ndatos_semilla.fillna('', inplace=True)\n\n\n# In[750]:\n\n\ndatos_semilla = datos_semilla.drop(datos_semilla[(datos_semilla[\"trafico.location\"]=='')].index)\n\n\n# ### leyendo indice cambium-devicedevices\n\n# Se lee la informaciÃ³n de los dispositivos de red monitoreados por Cambium. En esta lectura no hay referencia de fechas ya que solo hay una ocurrencia por MAC de dispositivo de red.\n# \n# * site_id es la llave para cruzar con cada centro de conexiÃ³n.\n# * mac, IP y name son datos bÃ¡sicos del dispositivo.\n# * ap_group identifica los dispositivos como INDOOR u OUTDOOR\n\n# In[751]:\n\n\ntotal_docs = 30000\ntry:\n    response = es.search(\n        index= parametros.cambium_d_d_index,\n        body={\n                    \"_source\": [\"site_id\",\"mac\",\"ip\",\"ap_group\",\"name\"]  \n                  , \"query\": {\n                    \"match_all\": {}\n                  }\n        },\n        size=total_docs\n    )\n    #print(es.info())\n    elastic_docs = response[\"hits\"][\"hits\"]\n#     fields = {}\n#     for num, doc in enumerate(elastic_docs):\n#         source_data = doc[\"_source\"]\n#         for key, val in source_data.items():\n#             try:\n#                 fields[key] = np.append(fields[key], val)\n#             except KeyError:\n#                 fields[key] = np.array([val])\n\n#     datos_dev = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ])) #pd.DataFrame(fields)\n    \n    datos_dev = pd.DataFrame([x[\"_source\"] for x in elastic_docs])\nexcept:\n    exit()\n\n\n# In[752]:\n\n\ndatos_dev['site_id'] = datos_dev['site_id'].str.strip()\n\n\n# Se descartan registros con site_id vacios y se limpian los NaN del dataframe\n\n# In[753]:\n\n\ndatos_dev.dropna(subset=['site_id'])\ndatos_dev.fillna('', inplace=True)\ndatos_dev = datos_dev.drop(datos_dev[(datos_dev['site_id']=='')].index)\ndatos_dev.sort_values(['site_id','ap_group'], inplace=True)\n\n\n# Se limpian datos mal formados de ap_group\n\n# In[754]:\n\n\ndatos_dev['ap_group'] = datos_dev['ap_group'].str.split(\"-\", n = 1, expand = True)[0]\ndatos_dev['ap_group'] = datos_dev['ap_group'].str.split(\"_\", n = 1, expand = True)[0]\ndatos_dev['ap_group'] = datos_dev['ap_group'].str.split(\".\", n = 1, expand = True)[0]\ndatos_dev = datos_dev.drop(datos_dev[(datos_dev['ap_group']=='')].index)\n\n\n# In[755]:\n\n\ndatos_dev = datos_dev.drop_duplicates('mac')\n\n\n# Se renombran campos segÃºn formato del indice final\n\n# In[756]:\n\n\ndatos_dev = datos_dev.rename(columns={'ap_group': 'trafico.apGroup'\n                                        , 'ip': 'trafico.IP'\n                                        , 'mac' : 'trafico.macRed'\n                                        , 'name' : 'trafico.deviceName'})\n\n\n# ### Trae la ultima fecha para control de ejecuciÃ³n\n\n# Cuando en el rango de tiempo de la ejecuciÃ³n, no se insertan nuevos valores, las fecha maxima en indice mintic no aumenta, por tanto se usa esta fecha de control para garantizar que incremente el bucle de ejecuciÃ³n\n\n# In[757]:\n\n\ntotal_docs = 1\ntry:\n    response = es.search(\n        index= indice_control,\n        body={\n               \"_source\": [\"trafico.fechaControl\"],\n              \"query\": {\n                \"bool\": {\n                  \"filter\": [\n                  {\n                    \"exists\": {\n                      \"field\":\"jerarquia_tablero_trafico\"\n                    }\n                  }\n                  ]\n                }\n              }\n        },\n        size=total_docs\n    )\n    #print(es.info())\n    elastic_docs = response[\"hits\"][\"hits\"]\n    fields = {}\n    for num, doc in enumerate(elastic_docs):\n        fecha_ejecucion = doc[\"_source\"]['trafico.fechaControl']\nexcept:\n    fecha_ejecucion = '2021-05-01 00:00:00'\nif response[\"hits\"][\"hits\"] == []:\n    fecha_ejecucion = '2021-05-01 00:00:00'\nprint(\"ultima fecha para control de ejecucion:\",fecha_ejecucion)\n\n\n# ## Se lee la informaciÃ³n de cambium device performance\n\n#  Se toma los valores de dispositivos de red y su desempeÃ±o.\n#  * mac del dispositivo de red\n#  * timestamp es la fecha y hora de la mediciÃ³n\n#  * radio.* volumen de datos descargados(r) y cargados(t)\n\n# In[758]:\n\n\ndef traePerformance(fecha_max,fecha_tope):\n    total_docs = 5000000\n    response = es.search(\n        index= parametros.cambium_d_p_index,\n        body={\n                \"_source\": [\"mac\",\"timestamp\",\"radio.5ghz.rx_bps\",\n                           \"radio.5ghz.tx_bps\",\"radio.24ghz.rx_bps\"\n                          ,\"radio.24ghz.tx_bps\"]\n              , \"query\": {\n                  \"range\": {\n                    \"timestamp\": {\n                      \"gte\": fecha_max,\n                      \"lt\": fecha_tope\n                    }\n                  }\n              }\n        },\n        size=total_docs\n    )\n    elastic_docs = response[\"hits\"][\"hits\"]\n#     fields = {}\n#     for num, doc in enumerate(elastic_docs):\n#         source_data = doc[\"_source\"]\n#         for key, val in source_data.items():\n#             try:\n#                 fields[key] = np.append(fields[key], val)\n#             except KeyError:\n#                 fields[key] = np.array([val])\n\n#     return pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ]))\n\n    return pd.DataFrame([x[\"_source\"] for x in elastic_docs])\n\n\n# ### Lanzando  ejecuciÃ³n de consulta\n\n# * Se calcula rango en base a la fecha de control. Para este caso es de 10 minutos.\n# * Se ejecuta la funciÃ³n de consulta con el rango de fechas.\n# * Si no retorna datos se incrementa el rango y se ejecuta nuevamente. Este proceso se repite hasta conseguir datos o hasta que el rango de ejecuciÃ³n alcance la fecha y hora actual.\n\n# In[759]:\n\n\nfecha_max_mintic = fecha_ejecucion\nfecha_tope_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)-timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\ndatos_performance = traePerformance(fecha_max_mintic,fecha_tope_mintic)\n\nif datos_performance is None or datos_performance.empty:\n    while (datos_performance is None or datos_performance.empty) and ((datetime.strptime(fecha_max_mintic[0:10], '%Y-%m-%d').strftime(\"%Y-%m-%d %H:%M:%S\")) < str(now.strftime(\"%Y-%m-%d %H:%M:%S\"))):\n        fecha_max_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        fecha_tope_mintic = (datetime.strptime(fecha_tope_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        datos_performance = traePerformance(fecha_max_mintic,fecha_tope_mintic)\nelse:\n    pass\n\n\n# funcion para insertar en indice: \n\n# In[760]:\n\n\nuse_these_keys = ['trafico.nomCentroDigital',\n                  'trafico.codISO',\n                  'trafico.localidad',\n                  'trafico.siteID',\n                  'trafico.nombreDepartamento',\n                  'trafico.sistemaEnergia',\n                  'trafico.nombreMunicipio',\n                  'trafico.idBeneficiario',\n                  'trafico.location',\n                  'trafico.apGroup',\n                  'trafico.IP',\n                  'trafico.deviceName',\n                  'trafico.macRed',\n                  #'trafico.status.macRed',\n                  'trafico.totales.fechaControl',\n                  'trafico.totales.traficoIN',\n                  'trafico.totales.traficoOUT',\n                  'trafico.totales.consumoGB',\n                  'trafico.totales.promedioIN',\n                  'trafico.totales.promedioOUT',\n                  'trafico.totales.promedioConsumo',\n                  'trafico.totales.fecha',\n                  'trafico.totales.anyo',\n                  'trafico.totales.mes',\n                  'trafico.totales.dia',\n                  'trafico.totales.hora',\n                  'trafico.totales.minuto',\n                  'nombreDepartamento',\n                    'nombreMunicipio',\n                    'idBeneficiario',\n                    'fecha',\n                    'anyo',\n                    'mes',\n                    'dia',\n                  '@timestamp']\ndef doc_generator(df):\n    df_iter = df.iterrows()\n    for index, document in df_iter:\n        yield {\n                \"_index\": indice, \n                \"_id\": f\"{'consumo-' + document['trafico.siteID'] + '-' + document['trafico.macRed'] + '-' +document['trafico.totales.fechaControl']+'-'+str(random.randrange(10000))}\",\n                \"_source\": filterKeys(document),\n            }\n\n\n# # Insertando consumo a indice \n\n# * Calculo de indicadores de consumos para cada AP. \n# * Se toman los valores de rx y tx como descarga y carga\n# * de datos_dev se toma el site_id y el ap_group\n\n# In[761]:\n\n\ntry:\n    datos_performance.drop_duplicates(inplace=True)\n    datos_performance['fecha_control'] = datos_performance[\"timestamp\"].str[0:-4] + '0:00'\n    datos_performance.rename(columns={'mac': 'trafico.macRed'}, inplace=True)\n    datos_performance.replace('','0',inplace=True)\n    datos_performance.fillna({'radio.5ghz.rx_bps':0, 'radio.5ghz.tx_bps':0,\n                      'radio.24ghz.rx_bps':0, 'radio.24ghz.tx_bps':0 },inplace=True)\n    datos_performance[['radio.5ghz.rx_bps','radio.5ghz.tx_bps','radio.24ghz.rx_bps','radio.24ghz.tx_bps']] = datos_performance[['radio.5ghz.rx_bps','radio.5ghz.tx_bps','radio.24ghz.rx_bps','radio.24ghz.tx_bps']].astype(int)\n\n    aux_performance=datos_performance[['trafico.macRed','fecha_control'\n                                       ,'radio.5ghz.rx_bps'\n                                       ,'radio.5ghz.tx_bps'\n                                       ,'radio.24ghz.rx_bps'\n                                       ,'radio.24ghz.tx_bps']].groupby(['trafico.macRed','fecha_control']).agg(['sum']).reset_index()\n    aux_performance.columns = aux_performance.columns.droplevel(1)\n    aux_performance['trafico.totales.traficoIN_aux'] = aux_performance['radio.5ghz.rx_bps'] + aux_performance['radio.24ghz.rx_bps']\n    aux_performance['trafico.totales.traficoOUT_aux'] = aux_performance['radio.5ghz.tx_bps'] + aux_performance['radio.24ghz.tx_bps']\n    \n    aux_performance = pd.merge(aux_performance, datos_dev, on='trafico.macRed',how='inner')\n    mintic_02 = pd.merge(datos_semilla,  aux_performance, on='site_id',how='inner')\n    \n        ## Calculo del promedio \n    aux_performance['trafico.totales.promedioIN'] = round((aux_performance['trafico.totales.traficoIN_aux']/float(1<<30)),6)\n    aux_performance['trafico.totales.promedioOUT'] = round((aux_performance['trafico.totales.traficoOUT_aux']/float(1<<30)),6)\n    aux_performance['trafico.totales.promedioConsumo'] = aux_performance['trafico.totales.promedioIN'] + aux_performance['trafico.totales.promedioOUT']\n    #Se totaliza para la sede completa\n    aux_performance['trafico.totales.promedioConsumo'] = round(aux_performance['trafico.totales.promedioConsumo'],6)\n    \n    #La informaciÃ³n de trÃ¡fico se convierte a GigaBytes y se toman 6 decimales\n    mintic_02['trafico.totales.traficoIN'] = round((mintic_02['trafico.totales.traficoIN_aux']/float(1<<30)),6)\n    mintic_02['trafico.totales.traficoOUT'] = round((mintic_02['trafico.totales.traficoOUT_aux']/float(1<<30)),6)\n    mintic_02['trafico.totales.consumoGB'] = mintic_02['trafico.totales.traficoIN'] + mintic_02['trafico.totales.traficoOUT']\n    #Se totaliza entrante y saliente\n    mintic_02['trafico.totales.consumoGB'] = round(mintic_02['trafico.totales.consumoGB'],6)\n\n    ### Generando columnas con fecha, anyo, mes, dia, hora y minuto por separado\n    mintic_02[\"trafico.totales.fecha\"] = mintic_02[\"fecha_control\"].str.split(\" \", n = 1, expand = True)[0]\n    mintic_02[\"trafico.totales.hora\"] = mintic_02[\"fecha_control\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[0]\n    mintic_02[\"trafico.totales.minuto\"] = mintic_02[\"fecha_control\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[1]\n    mintic_02[\"trafico.totales.anyo\"] = mintic_02[\"trafico.totales.fecha\"].str[0:4]\n    mintic_02[\"trafico.totales.mes\"] = mintic_02[\"trafico.totales.fecha\"].str[5:7]\n    mintic_02[\"trafico.totales.dia\"] = mintic_02[\"trafico.totales.fecha\"].str[8:10]\n    ### Renombrado de campos\n    mintic_02.rename(columns={'site_id': 'trafico.siteID'\n                             ,'fecha_control' : 'trafico.totales.fechaControl'}, inplace=True)\n\n    \n    aux_performance=aux_performance.rename(columns={'site_id' : 'trafico.siteID',                                                 'fecha_control':'trafico.totales.fechaControl'})\n\n\n    ##nulos a cero\n    mintic_02.fillna({'trafico.totales.consumoGB':0,\n                      'trafico.totales.traficoIN':0,\n                      'trafico.totales.traficoOUT':0\n                      },inplace=True)\n    #cambia valores a tipo float\n    mintic_02[['trafico.totales.consumoGB','trafico.totales.traficoIN','trafico.totales.traficoOUT']] = mintic_02[['trafico.totales.consumoGB','trafico.totales.traficoIN','trafico.totales.traficoOUT']].astype(float)\n    \n    mintic_02['nombreDepartamento'] = mintic_02['trafico.nombreDepartamento']\n    mintic_02['nombreMunicipio'] = mintic_02['trafico.nombreMunicipio']\n    mintic_02['idBeneficiario'] = mintic_02['trafico.idBeneficiario']\n    mintic_02['fecha'] = mintic_02['trafico.totales.fecha']\n    mintic_02['anyo'] = mintic_02['trafico.totales.anyo']\n    mintic_02['mes'] = mintic_02['trafico.totales.mes']\n    mintic_02['dia'] = mintic_02['trafico.totales.dia']\n    mintic_02['@timestamp'] = now.isoformat()\n    \n    aux_performance = aux_performance[['trafico.siteID'\n                              ,'trafico.macRed'\n                              ,'trafico.totales.fechaControl'\n                              ,'trafico.totales.promedioIN'\n                              ,'trafico.totales.promedioOUT'\n                              ,'trafico.totales.promedioConsumo']]\n    \n    mintic_02 = pd.merge(mintic_02,aux_performance, \n                        on=['trafico.siteID',\n                            'trafico.macRed',\n                            'trafico.totales.fechaControl'],how='left')\n\n    salida = helpers.bulk(es, doc_generator(mintic_02))\n    print(\"Fecha: \", now,\"- Datos Trafico Consumos en indice principal:\",salida[0])\nexcept Exception as e:\n    print(e)\n    print(\"Fecha: \", now,\"- No se insertaron datos de consumos en indice principal\")\n\n\n# ## En otra  jerarquÃ­a se escriben los dispositivos conectados\n\n# Se toma el dataframe del proceso anterior para realizar el siguiente proceso:\n# * Se cuentan la cantidad de dispositivos WAN/LAN (OUTDOOR/INDOOR), agrupando por fecha y sitio\n# * Cantidad dispositivos WAN/LAN conectados se calcula validando cuando son OUTDOOR/INDOOR y tienen trafico(traficoOUT)\n# * Cantidad de dispositivos desconectados, restando los dos anteriores\n# \n# Datos generados\n# * trafico.totales.cantDevWAN\n# * trafico.totales.cantDevLAN\n# * trafico.totales.cantDevConectadosWAN\n# * trafico.totales.cantDevDesconectadosWAN\n# * trafico.totales.cantDevConectadosLAN\n# * trafico.totales.cantDevDesconectadosLAN\n# * trafico.totales.cantDev\n\n# In[762]:\n\n\ntry:\n    mintic_03 = mintic_02[['trafico.nomCentroDigital',\n                      'trafico.codISO',\n                      'trafico.localidad',\n                      'trafico.siteID',\n                      'trafico.nombreDepartamento',\n                      'trafico.sistemaEnergia',\n                      'trafico.nombreMunicipio',\n                      'trafico.idBeneficiario',\n                      'trafico.location',\n                      'trafico.apGroup',\n                      'trafico.macRed',\n                      'trafico.totales.fechaControl',\n                      'trafico.totales.fecha',\n                      'trafico.totales.anyo',\n                      'trafico.totales.mes',\n                      'trafico.totales.dia',\n                      'trafico.totales.hora',\n                      'trafico.totales.minuto',\n                      'trafico.totales.traficoIN',\n                      'trafico.totales.traficoOUT',\n                      'trafico.totales.consumoGB',\n                      'trafico.totales.promedioIN',\n                      'trafico.totales.promedioOUT',\n                      'trafico.totales.promedioConsumo']].groupby(['trafico.nomCentroDigital',\n                                                              'trafico.codISO',\n                                                              'trafico.localidad',\n                                                              'trafico.siteID',\n                                                              'trafico.nombreDepartamento',\n                                                              'trafico.sistemaEnergia',\n                                                              'trafico.nombreMunicipio',\n                                                              'trafico.idBeneficiario',\n                                                              'trafico.location',\n                                                              'trafico.apGroup',\n                                                              'trafico.macRed',\n                                                              'trafico.totales.fechaControl',\n                                                              'trafico.totales.fecha',\n                                                              'trafico.totales.anyo',\n                                                              'trafico.totales.mes',\n                                                              'trafico.totales.dia',\n                                                              'trafico.totales.hora',\n                                                              'trafico.totales.promedioIN',\n                                                              'trafico.totales.promedioOUT',\n                                                              'trafico.totales.promedioConsumo',\n                                                              'trafico.totales.minuto']).agg(['sum']).reset_index()\n    mintic_03.columns = mintic_03.columns.droplevel(1)\n    mintic_03.rename(columns={'trafico.totales.traficoIN' : 'trafico.totales.sitio.traficoIN'\n                          ,'trafico.totales.traficoOUT' : 'trafico.totales.sitio.traficoOUT'\n                          ,'trafico.totales.consumoGB' : 'trafico.totales.sitio.consumoGB'\n                         }, inplace=True)\nexcept:\n    pass\n\n\n# Funcion para insertar en indice la cantidad de dispositivos conectados \n# * la lista use_these_keys se usa para referenciar cuales campos del dataframe irÃ¡n al indice final. si los datos no se declaran en este, no se insertarÃ¡n\n# \n\n# In[763]:\n\n\nuse_these_keys = ['trafico.nomCentroDigital',\n                  'trafico.codISO',\n                  'trafico.localidad',\n                  'trafico.siteID',\n                  'trafico.nombreDepartamento',\n                  'trafico.sistemaEnergia',\n                  'trafico.nombreMunicipio',\n                  'trafico.idBeneficiario',\n                  'trafico.location',\n                  'trafico.apGroup',\n                  'trafico.totales.fechaControl',\n                  'trafico.totales.cantDevWAN',\n                  'trafico.totales.cantDevConectadosWAN',\n                  'trafico.totales.cantDevDesconectadosWAN',\n                  'trafico.totales.cantDevLAN',\n                  'trafico.totales.cantDevConectadosLAN',\n                  'trafico.totales.cantDevDesconectadosLAN',\n                  'trafico.totales.cantDev',\n                  'trafico.totales.cantDevConectados',\n                  'trafico.totales.cantDevDesconectados',\n                  'trafico.totales.fecha',\n                  'trafico.totales.anyo',\n                  'trafico.totales.mes',\n                  'trafico.totales.dia',\n                  'trafico.totales.hora',\n                  'trafico.totales.minuto',\n                  'trafico.totales.sitio.traficoIN',\n                  'trafico.totales.sitio.traficoOUT',\n                  'trafico.totales.sitio.consumoGB',\n                  'trafico.totales.promedioIN',\n                  'trafico.totales.promedioOUT',\n                  'trafico.totales.promedioConsumo',\n                  '@timestamp']\n\ndef doc_generator_dis(df):\n    df_iter = df.iterrows()\n    for index, document in df_iter:\n        yield {\n                \"_index\": indice, \n                \"_id\": f\"{'Conectados-' + document['trafico.siteID'] + '-' +document['trafico.totales.fechaControl']+'-'+str(random.randrange(10000))}\",\n                \"_source\": filterKeys(document),\n            }\n\n\n# # Insertando cantidad de dispositivos conectados\n\n# In[764]:\n\n\ntry:\n    cantDevWAN = mintic_02[(mintic_02['trafico.apGroup']=='OUTDOOR')][['trafico.totales.fechaControl','trafico.macRed','trafico.siteID']].groupby(['trafico.siteID','trafico.totales.fechaControl'])['trafico.macRed'].nunique().reset_index()    \n    cantDevWAN.rename(columns={'trafico.macRed': 'trafico.totales.cantDevWAN'}, inplace=True)\n    mintic_03 = pd.merge(mintic_03,  cantDevWAN, on=['trafico.siteID','trafico.totales.fechaControl'],how='left')\n\n    cantDevConectadosWAN = mintic_02[(mintic_02['trafico.totales.traficoOUT']>0) & (mintic_02['trafico.apGroup']=='OUTDOOR')][['trafico.totales.fechaControl','trafico.macRed','trafico.siteID']].groupby(['trafico.siteID','trafico.totales.fechaControl'])['trafico.macRed'].nunique().reset_index()\n    cantDevConectadosWAN.rename(columns={'trafico.macRed': 'trafico.totales.cantDevConectadosWAN'}, inplace=True)\n    mintic_03 = pd.merge(mintic_03, cantDevConectadosWAN, on=['trafico.siteID','trafico.totales.fechaControl'],how='left')\n    mintic_03.fillna({'trafico.totales.cantDevWAN':0,\n                      'trafico.totales.cantDevConectadosWAN':0\n                      },inplace=True)\n    mintic_03['trafico.totales.cantDevDesconectadosWAN'] = mintic_03['trafico.totales.cantDevWAN'] - mintic_03['trafico.totales.cantDevConectadosWAN']\n\n    #La misma lÃ³gica se aplica para calcular las cantidades para dispositivos LAN, pero filtrando los INDOOR\n    cantDevLAN = mintic_02[(mintic_02['trafico.apGroup']=='INDOOR')][['trafico.totales.fechaControl','trafico.macRed','trafico.siteID']].groupby(['trafico.siteID','trafico.totales.fechaControl'])['trafico.macRed'].nunique().reset_index()\n    cantDevLAN.rename(columns={'trafico.macRed': 'trafico.totales.cantDevLAN'}, inplace=True)\n    mintic_03 = pd.merge(mintic_03,  cantDevLAN, on=['trafico.siteID','trafico.totales.fechaControl'],how='left')\n\n    cantDevConectadosLAN = mintic_02[~(mintic_02['trafico.totales.traficoIN']>0) & (mintic_02['trafico.apGroup']=='INDOOR')][['trafico.totales.fechaControl','trafico.macRed','trafico.siteID']].groupby(['trafico.siteID','trafico.totales.fechaControl'])['trafico.macRed'].nunique().reset_index()\n    cantDevConectadosLAN.rename(columns={'trafico.macRed': 'trafico.totales.cantDevConectadosLAN'}, inplace=True)\n\n    mintic_03 = pd.merge(mintic_03, cantDevConectadosLAN, on=['trafico.siteID','trafico.totales.fechaControl'],how='left')\n    mintic_03.fillna({'trafico.totales.cantDevLAN':0,\n                      'trafico.totales.cantDevConectadosLAN':0\n                      },inplace=True)\n    mintic_03['trafico.totales.cantDevDesconectadosLAN'] = mintic_03['trafico.totales.cantDevLAN'] - mintic_03['trafico.totales.cantDevConectadosLAN']\n\n    mintic_03.fillna({'trafico.totales.cantDevConectadosWAN':0,\n                      'trafico.totales.cantDevDesconectadosWAN':0,\n                      'trafico.totales.cantDevConectadosLAN':0,\n                      'trafico.totales.cantDevDesconectadosLAN':0,\n                      'trafico.totales.sitio.traficoIN':0,\n                      'trafico.totales.sitio.traficoOUT':0,\n                      'trafico.totales.sitio.consumoGB':0\n                      },inplace=True)\n    #cambia valores a tipo float \n    mintic_03[['trafico.totales.sitio.consumoGB','trafico.totales.sitio.traficoIN','trafico.totales.sitio.traficoOUT']] = mintic_03[['trafico.totales.sitio.consumoGB','trafico.totales.sitio.traficoIN','trafico.totales.sitio.traficoOUT']].astype(float)\n    \n    mintic_03['trafico.totales.cantDev'] = mintic_03['trafico.totales.cantDevLAN'] + mintic_03['trafico.totales.cantDevWAN']\n    mintic_03[['trafico.totales.cantDev','trafico.totales.cantDevConectadosWAN','trafico.totales.cantDevDesconectadosWAN','trafico.totales.cantDevConectadosLAN','trafico.totales.cantDevDesconectadosLAN']] = mintic_03[['trafico.totales.cantDev','trafico.totales.cantDevConectadosWAN','trafico.totales.cantDevDesconectadosWAN','trafico.totales.cantDevConectadosLAN','trafico.totales.cantDevDesconectadosLAN']].astype(int)\n\n    mintic_03['trafico.totales.cantDevConectados'] = mintic_03['trafico.totales.cantDevConectadosWAN'] + mintic_03['trafico.totales.cantDevConectadosLAN']\n    mintic_03['trafico.totales.cantDevDesconectados'] = mintic_03['trafico.totales.cantDevDesconectadosLAN'] + mintic_03['trafico.totales.cantDevDesconectadosWAN']\n    mintic_03[['trafico.totales.cantDevConectados'\n              ,'trafico.totales.cantDevDesconectados'\n              ,'trafico.totales.cantDevWAN'\n              ,'trafico.totales.cantDevLAN']] = mintic_03[['trafico.totales.cantDevConectados'\n                                                          ,'trafico.totales.cantDevDesconectados'\n                                                          ,'trafico.totales.cantDevWAN'\n                                                          ,'trafico.totales.cantDevLAN']].astype(int)    \n    mintic_03['@timestamp'] = now.isoformat()\n    \n    if ('mintic_03' in locals() or 'mintic_03' in globals()) and (not mintic_03.empty):\n        pass\n    salida = helpers.bulk(es, doc_generator_dis(mintic_03))\n    \n    print(\"Fecha: \", now,\"- Datos Dispositivos Conectados en indice principal:\",salida[0])\nexcept Exception as e:\n    print(e)\n    print(\"Fecha: \", now,\"- No se insertaron datos de dispositivos conectados en indice principal\")\n\n\n# In[765]:\n\n\nuse_these_keys = ['trafico.nomCentroDigital',\n                  'trafico.codISO',\n                  'trafico.localidad',\n                  'trafico.siteID',\n                  'trafico.nombreDepartamento',\n                  'trafico.sistemaEnergia',\n                  'trafico.nombreMunicipio',\n                  'trafico.idBeneficiario',\n                  'trafico.location',\n                  'trafico.apGroup',\n                  'trafico.totales.fechaControl',\n                  #'trafico.totales.cantDevWAN',\n                  #'trafico.totales.cantDevConectadosWAN',\n                  #'trafico.totales.cantDevDesconectadosWAN',\n                  #'trafico.totales.cantDevLAN',\n                  #'trafico.totales.cantDevConectadosLAN',\n                  #'trafico.totales.cantDevDesconectadosLAN',\n                  #'trafico.totales.cantDev',\n                  #'trafico.totales.cantDevConectados',\n                  #'trafico.totales.cantDevDesconectados',\n                  'trafico.totales.fecha',\n                  'trafico.totales.anyo',\n                  'trafico.totales.mes',\n                  'trafico.totales.dia',\n                  'trafico.totales.hora',\n                  'trafico.totales.minuto',\n                  #'trafico.totales.sitio.traficoIN',\n                  #'trafico.totales.sitio.traficoOUT',\n                  #'trafico.totales.sitio.consumoGB',\n                  #'trafico.totales.promedioIN',\n                  #'trafico.totales.promedioOUT',\n                  #'trafico.totales.promedioConsumo',\n                  'trafico.totales.totalConexiones',\n                  '@timestamp']\n\ndef doc_generator_dis(df):\n    df_iter = df.iterrows()\n    for index, document in df_iter:\n        yield {\n                \"_index\": indice, \n                \"_id\": f\"{'Conectados-' + document['trafico.siteID'] + '-' +document['trafico.totales.fechaControl']+'-'+str(random.randrange(10000))}\",\n                \"_source\": filterKeys(document),\n            }\n\n\n# ### Traer datos de ohmyfi-detalleconexiones\n\n# El rango de fechas serÃ¡ definido tomando de referencia la ultima fechahora del indice mintic-concat.\n# \n# Campos extaidos:\n# * fechahora de la conexiÃ³n\n# * fecha_control es un campo calculado a partir de fechahora. es lo mismo pero con el valor de minuto redondeado a 0.\n# * ugar_cod clave para asociar con semilla\n# * mac_usuario asociado al dispositivo que realizÃ³ la conexiÃ³n\n\n# In[766]:\n\n\ndef trae_conexiones(fecha_ini,fecha_fin):\n    total_docs = 5000000\n#     print(fecha_ini)\n#     print(fecha_fin)\n    response = es.search(\n        index= parametros.ohmyfi_d_c_index,\n        body={\n                \"_source\": [\"fechahora\",\"fecha_control\",\"lugar\",\"lugar_cod\",\"mac_usuario\", \"dispositivo\"\n                            ,\"sistema_operativo\",'tipodoc','documento']\n                , \"query\": {\n                  \"range\": {\n                    \"fechahora\": {\n                      \"gte\": fecha_ini,\n                      \"lt\": fecha_fin\n                    }\n                  }\n              }\n        },\n        size=total_docs\n        #, request_timeout=300\n    )\n    elastic_docs = response[\"hits\"][\"hits\"]\n#     fields = {}\n#     for num, doc in enumerate(elastic_docs):\n#         source_data = doc[\"_source\"]\n#         for key, val in source_data.items():\n#             try:\n#                 fields[key] = np.append(fields[key], val)\n#             except KeyError:\n#                 fields[key] = np.array([val])\n\n#     return pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fields.items() ]))\n\n    return pd.DataFrame([x[\"_source\"] for x in elastic_docs])\n\n\n# ### Se acotan los rangos de fecha por eficiencia\n\n# * Se calcula rango en base a la fecha de control. Para este caso es de 10 minutos.\n# * Se ejecuta la funciÃ³n de consulta con el rango de fechas.\n# * Si no retorna datos se incrementa el rango y se ejecuta nuevamente. Este proceso se repite hasta conseguir datos o hasta que el rango de ejecuciÃ³n alcance la fecha y hora actual.\n\n# In[767]:\n\n\nfecha_max_mintic = fecha_ejecucion\nfecha_tope_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)-timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\ndatos_det_conex_completo = trae_conexiones(fecha_max_mintic,fecha_tope_mintic)\n\nif datos_det_conex_completo is None or datos_det_conex_completo.empty:\n    while (datos_det_conex_completo is None or datos_det_conex_completo.empty) and ((datetime.strptime(fecha_max_mintic[0:10], '%Y-%m-%d').strftime(\"%Y-%m-%d %H:%M:%S\")) < str(now.strftime(\"%Y-%m-%d %H:%M:%S\"))):\n        fecha_max_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        fecha_tope_mintic = (datetime.strptime(fecha_tope_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        datos_det_conex_completo = trae_conexiones(fecha_max_mintic,fecha_tope_mintic)\nelse:\n    pass\n\n\n# In[768]:\n\n\ndatos_det_conex_completo['lugar_cod'] = datos_det_conex_completo['lugar_cod'].str.strip()\n\n\n# In[769]:\n\n\ndatos_det_conex_completo.drop_duplicates(subset=[\"fecha_control\",\"lugar\",\"lugar_cod\",\"mac_usuario\", \"dispositivo\",\"sistema_operativo\",'tipodoc','documento'],inplace=True)\n\n\n# ### contanto conexiones por lugar y fecha\n\n# Para cada centro, y fecha control, se cuenta la cantidad de conexiones. Una vez combinado con semilla, se disponibiliza el filtrado por departamento, municipio y centro de conexiÃ³n. El campo generado es:\n# * trafico.totales.totalConexiones\n\n# In[770]:\n\n\ndatos_det_conex=datos_det_conex_completo[[\"fechahora\",\"fecha_control\",\"lugar_cod\"]].groupby(['lugar_cod','fecha_control']).agg(['count']).reset_index()\ndatos_det_conex.columns = datos_det_conex.columns.droplevel(1)\n\n\n# ### renombrado de columnas en detalle conexiones\n\n# In[771]:\n\n\ndatos_det_conex = datos_det_conex.rename(columns={'fechahora' : 'trafico.totales.totalConexiones','lugar_cod':'site_id'})\n\n\n# ### Combinando detalle de conexiones con dispositivos usuario y red\n\n# In[772]:\n\n\ntotal_docs = 30000000\nresponse = es.search(\n    index= parametros.cambium_d_c_index,\n    body={\n            \"_source\": [\"mac\",\"ap_mac\", 'manufacturer',\"radio.band\",'radio.rx_bytes','radio.tx_bytes'],\n              \"query\": {\n                \"bool\": {\n                  \"filter\": [\n                  {\n                    \"exists\": {\n                      \"field\":\"mac\"\n                    }\n                  }\n                  ]\n                }\n              }\n    },\n    size=total_docs\n)\nelastic_docs = response[\"hits\"][\"hits\"]\n\ndatos_dev_clients= pd.DataFrame([x[\"_source\"] for x in elastic_docs])\n\ndatos_dev_clients.drop_duplicates(inplace=True)\n\n\n# * Se renombran campos de clientes\n# * se incorpora informaciones de clientes a detalle conexiones\n\n# In[773]:\n\n\ndatos_dev_clients = datos_dev_clients.rename(columns={'ap_mac' : 'trafico.macRed','mac' : 'mac_usuario'})\ndatos_det_conex_completo = pd.merge(datos_det_conex_completo,  datos_dev_clients, on='mac_usuario',how='left')\ndatos_det_conex_completo = pd.merge(datos_det_conex_completo,datos_dev[['trafico.macRed','trafico.apGroup','trafico.IP','trafico.deviceName']],on='trafico.macRed', how='left')\n\n\n# ## calculando total de conexiones\n\n# tiene la informaciÃ³n de semilla, total de conexiones, alarmas, performance de AP y recurrencia de usuarios. Para obtener un registro unico para cada site_id, ap_group y fecha_control, se usa el data frame con fechas unicas (fechas_semilla)\n\n# In[774]:\n\n\ntry:\n    total_conexiones =  datos_det_conex_completo[[\"fechahora\",\"fecha_control\",\"lugar_cod\"\n                                                  ,\"trafico.macRed\",'trafico.apGroup'\n                                                  ,'trafico.IP', 'trafico.deviceName'\n                                                 ]].groupby(['lugar_cod','fecha_control'\n                                                        ,\"trafico.macRed\",'trafico.apGroup'\n                                                        ,'trafico.IP', 'trafico.deviceName']).agg(['count']).reset_index()\n    total_conexiones.columns = total_conexiones.columns.droplevel(1)\n    total_conexiones.rename(columns={'fechahora': 'trafico.totales.totalConexiones'\n                                    , 'lugar_cod' : 'site_id'}, inplace=True)\n    mintic_01 = pd.merge(datos_semilla,  total_conexiones, on='site_id',how='inner')\n    mintic_01.fillna({'trafico.totales.totalConexiones': 0}, inplace=True)\n    mintic_01['trafico.totales.totalConexiones'] = mintic_01['trafico.totales.totalConexiones'].astype(int)\n    mintic_01.rename(columns={'site_id': 'trafico.siteID'\n                             ,'fecha_control' : 'trafico.totales.fechaControl'}, inplace=True)\n\n    try:\n        mintic_01[\"trafico.totales.fecha\"] = mintic_01[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[0]\n    except:\n        mintic_01[\"trafico.totales.fecha\"] = \"\"\n\n    try:\n        mintic_01[\"trafico.totales.hora\"] = mintic_01[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[0]\n    except:\n        mintic_01[\"trafico.totales.hora\"] = \"\"\n\n    try:\n        mintic_01[\"trafico.totales.minuto\"] = mintic_01[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[1]\n    except:\n        mintic_01[\"trafico.totales.minuto\"] = \"\"\n\n    try:\n        mintic_01[\"trafico.totales.anyo\"] = mintic_01[\"trafico.totales.fecha\"].str[0:4]\n    except:\n        mintic_01[\"trafico.totales.anyo\"] = \"\"\n\n    try:\n        mintic_01[\"trafico.totales.mes\"] = mintic_01[\"trafico.totales.fecha\"].str[5:7]\n    except:\n        mintic_01[\"trafico.totales.mes\"] = \"\"\n\n    try:\n        mintic_01[\"trafico.totales.dia\"] = mintic_01[\"trafico.totales.fecha\"].str[8:10]\n    except:\n        mintic_01[\"trafico.totales.dia\"] = \"\"\n\n    mintic_01['nombreDepartamento'] = mintic_01['trafico.nombreDepartamento']\n    mintic_01['nombreMunicipio'] = mintic_01['trafico.nombreMunicipio']\n    mintic_01['idBeneficiario'] = mintic_01['trafico.idBeneficiario']\n    mintic_01['fecha'] = mintic_01['trafico.totales.fecha']\n    mintic_01['anyo'] = mintic_01['trafico.totales.anyo']\n    mintic_01['mes'] = mintic_01['trafico.totales.mes']\n    mintic_01['dia'] = mintic_01['trafico.totales.dia']\n    mintic_01['@timestamp'] = now.isoformat()       \n\n    #mintic_01 = mintic_01[['trafico.siteID','trafico.totales.fechaControl','trafico.macRed','trafico.apGroup','trafico.totales.totalConexiones','@timestamp']]\n\n    # mintic_04=pd.merge(mintic_03,mintic_01,on=['trafico.siteID','trafico.apGroup','trafico.totales.fechaControl'],how='left')\n    total_conexiones.rename(columns={'site_id': 'trafico.siteID'\n                             ,'fecha_control' : 'trafico.totales.fechaControl'}, inplace=True)\n\n    #mintic_04=pd.merge(mintic_03,mintic_01,on=['trafico.siteID','trafico.apGroup','trafico.totales.fechaControl'],how='left')\n    salida = helpers.bulk(es, doc_generator_dis(mintic_01))\n    print(\"Fecha: \", now,\"- Datos Trafico en indice principal:\",salida[0])\nexcept Exception as e:\n    print(e)\n    print(\"Fecha: \", now,\"- Nada de Trafico para insertar en indice principal:\")\n\n\n# ## Se lee informaciÃ³n para usuarios recurrencia\n\n# Se calcula y agrega al indice principal:\n# * trafico.concurrenciaConexiones\n# \n# Se lee el indice recurrencia de conexiones y se compara con el flujo detalle conexiones para el rango dado. Si cruzan, se suma a la cuenta de recurrentes.\n\n# In[775]:\n\n\ntotal_docs = 5000000\nresponse = es.search(\n    index= parametros.ohmyfi_r_u_index,\n    body={\n            \"_source\": [\"ultima_conexion\", \"lugar_cod\", \"id_usuario\"]\n    },\n    size=total_docs\n)\n#print(es.info())\nelastic_docs = response[\"hits\"][\"hits\"]\ndatos_recurrencia = pd.DataFrame([x[\"_source\"] for x in elastic_docs])\n\n\n# In[776]:\n\n\ndatos_recurrencia['lugar_cod'] = datos_recurrencia['lugar_cod'].str.strip()\n\n\n# Se cuenta la cantidad de usuarios con mas de una conexiÃ³n\n\n# # Concurrencia usuario a indice\n\n# In[777]:\n\n\ntry:\n    datos_det_conex_completo.rename(columns={'mac_usuario':'id_usuario'}, inplace=True)\n    aux_recurrencia=datos_det_conex_completo[['lugar_cod','id_usuario']].groupby(['id_usuario']).agg(['count']).reset_index()\n    aux_recurrencia.columns = aux_recurrencia.columns.droplevel(1)\n    aux_recurrencia.rename(columns={'lugar_cod': 'contador'}, inplace=True)\n    aux_recurrencia = aux_recurrencia.drop(aux_recurrencia[(aux_recurrencia['contador'] < 2)].index)\n    datos_recurrencia = pd.merge(datos_det_conex_completo,  aux_recurrencia, on='id_usuario', how='inner')\n    datos_recurrencia = datos_recurrencia[['lugar_cod','fecha_control','id_usuario']].groupby(['lugar_cod','fecha_control']).agg(['count']).reset_index()\n    datos_recurrencia.columns = datos_recurrencia.columns.droplevel(1)\n    datos_recurrencia.rename(columns={'lugar_cod':'site_id'}, inplace=True)\n    datos_recurrencia = pd.merge(datos_semilla,  datos_recurrencia, on='site_id', how='inner')\n    datos_recurrencia.rename(columns={'site_id':'trafico.siteID'\n                                     ,'id_usuario': 'trafico.concurrenciaConexiones'\n                                     ,'fecha_control' : 'trafico.totales.fechaControl'}, inplace=True)\n    datos_recurrencia.fillna({'trafico.concurrenciaConexiones':0},inplace=True)\n    datos_recurrencia.fillna('', inplace=True)\n    #print(datos_recurrencia)\n    try:\n        datos_recurrencia[\"trafico.totales.fecha\"] = datos_recurrencia[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[0]\n    except Exception as e:\n        datos_recurrencia[\"trafico.totales.fecha\"] = \"\"\n        \n    datos_recurrencia[\"trafico.totales.anyo\"] = datos_recurrencia[\"trafico.totales.fecha\"].str[0:4]\n    try:\n        datos_recurrencia[\"trafico.totales.mes\"] = datos_recurrencia[\"trafico.totales.fecha\"].str[5:7]\n    except Exception as e:\n        datos_recurrencia[\"trafico.totales.mes\"] = \"\"\n    \n    try:\n        datos_recurrencia[\"trafico.totales.dia\"] = datos_recurrencia[\"trafico.totales.fecha\"].str[8:10]\n    except:\n        datos_recurrencia[\"trafico.totales.dia\"] = \"\"\n    \n    try:\n        datos_recurrencia[\"trafico.totales.hora\"] = datos_recurrencia[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[0]\n    except:\n        datos_recurrencia[\"trafico.totales.hora\"] = \"\"\n    \n    try:\n        datos_recurrencia[\"trafico.totales.minuto\"] = datos_recurrencia[\"trafico.totales.fechaControl\"].str.split(\" \", n = 1, expand = True)[1].str.split(\":\", n = 2, expand = True)[1]\n    except:\n        datos_recurrencia[\"trafico.totales.minuto\"] = ''\n    \n    datos_recurrencia['nombreDepartamento'] = datos_recurrencia['trafico.nombreDepartamento']\n    datos_recurrencia['nombreMunicipio'] = datos_recurrencia['trafico.nombreMunicipio']\n    datos_recurrencia['idBeneficiario'] = datos_recurrencia['trafico.idBeneficiario']\n    datos_recurrencia['fecha'] = datos_recurrencia['trafico.totales.fecha']\n    datos_recurrencia['anyo'] = datos_recurrencia['trafico.totales.anyo']\n    datos_recurrencia['mes'] = datos_recurrencia['trafico.totales.mes']\n    datos_recurrencia['dia'] = datos_recurrencia['trafico.totales.dia']\n    #print(\"eje111\")\n    datos_recurrencia['@timestamp'] = now.isoformat() \n    \n    #datos_recurrencia=datos_recurrencia[['trafico.siteID','trafico.totales.fechaControl','trafico.concurrenciaConexiones']]\n    \n    #mintic_03=pd.merge(mintic_04,datos_recurrencia,on=['trafico.siteID','trafico.totales.fechaControl'],how='left')\n    datos_recurrencia=pd.merge(mintic_01,datos_recurrencia,on=['trafico.siteID','trafico.totales.fechaControl'],how='left')\n    \n    #datos_recurrencia=datos_recurrencia[['trafico.siteID','trafico.totales.fechaControl','trafico.concurrenciaConexiones']]\n    #print(mintic_03)\n    \n    datos_recurrencia.fillna({'trafico.concurrenciaConexiones':0,\n                    },inplace=True)\n    datos_recurrencia[['trafico.concurrenciaConexiones']] = datos_recurrencia[['trafico.concurrenciaConexiones']].astype(int)\n    \n    #salida = helpers.bulk(es, doc_generator(datos_recurrencia))\n    #print(\"Fecha: \", now,\"- recurrencia de usuario a indice:\",salida[0])\nexcept Exception as e:\n    #print(\"Fecha: \", now,\"- Ninguna recurrencia de usuario para insertar en indice principal\")\n    pass\n\n\n# In[778]:\n\n\ndatos_recurrencia.rename(columns={'trafico.nomCentroDigital_x':'trafico.nomCentroDigital',\n                                  'trafico.idBeneficiario_x':'trafico.idBeneficiario',\n                                  'trafico.location_x':'trafico.location',\n                                  'trafico.totales.fecha_x':'trafico.totales.fecha',\n                                  'trafico.totales.hora_x':'trafico.totales.hora',\n                                  'trafico.totales.minuto_x':'trafico.totales.minuto',\n                                  'trafico.totales.anyo_x': 'trafico.totales.anyo',\n                                  'trafico.totales.mes_x' :'trafico.totales.mes',\n                                  'trafico.totales.dia_x' : 'trafico.totales.dia',\n                                  'fecha_x' : 'fecha',\n                                  'anyo_x' : 'anyo',\n                                  'mes_x' : 'mes',\n                                  'dia_x': 'dia'}, inplace=True)\n\n\n# In[779]:\n\n\ndatos_recurrencia=datos_recurrencia[['trafico.siteID',\n                                     'trafico.nomCentroDigital',\n                                     'trafico.idBeneficiario',\n                                     'trafico.location',\n                                     'trafico.totales.fechaControl',\n                                     'trafico.totales.fecha',\n                                     'trafico.totales.hora',\n                                     'trafico.totales.minuto',\n                                     'trafico.totales.anyo',\n                                     'trafico.totales.mes',\n                                     'trafico.totales.dia',\n                                     'fecha',\n                                     'anyo',\n                                     'mes',\n                                     'dia',\n                                     'trafico.concurrenciaConexiones'\n                                    ]]\n\n\n# # Insertando recurrencia de usuario en indice principal\n\n# la lista use_these_keys se usa para referenciar cuales campos del dataframe irÃ¡n al indice final. si los datos no se declaran en este, no se insertarÃ¡n\n\n# In[780]:\n\n\ntry:\n    use_these_keys = ['trafico.siteID',\n                                     'trafico.nomCentroDigital',\n                                     'trafico.idBeneficiario',\n                                     'trafico.location',\n                                     'trafico.totales.fechaControl',\n                                     'trafico.totales.fecha',\n                                     'trafico.totales.hora',\n                                     'trafico.totales.minuto',\n                                     'trafico.totales.anyo',\n                                     'trafico.totales.mes',\n                                     'trafico.totales.dia',\n                                     'fecha',\n                                     'anyo',\n                                     'mes',\n                                     'dia',\n                                     'trafico.concurrenciaConexiones',\n                                     '@timestamp']\n\n    datos_recurrencia['@timestamp'] = now.isoformat()\n    def doc_generator(df):\n        df_iter = df.iterrows()\n        for index, document in df_iter:\n            yield {\n                    \"_index\": indice, \n                    \"_id\": f\"{ 'Recurrencia-' + str(document['trafico.siteID']) + '-' + str(document['trafico.totales.fechaControl'])+ str(random.randrange(1000))}\",\n                    \"_source\": filterKeys(document),\n                }\n    salida = helpers.bulk(es, doc_generator(datos_recurrencia))\n    print(\"Fecha: \", now,\"- recurrencia de usuario a indice:\",salida[0])\nexcept Exception as e:\n    print(e)\n    print(\"Fecha: \", now,\"- Ninguna recurrencia de usuario para insertar en indice principal\")\n\n\n# ### Asociando datos de Speed test\n\n# Se tiene una lectura diara de velocidad para cada centro. Por tanto se debe cruzar con el fjulo principal, haciendo uso solo del aÃ±o, mes dÃ­a, sin incluir la hora.\n\n# ### FunciÃ³n para generar JSON compatible con ES\n\n# In[781]:\n\n\ndef traeVelocidad(fecha_max_mintic,fecha_tope_mintic):\n    total_docs = 10000\n    print(fecha_max_mintic)\n    print(fecha_tope_mintic)\n    response = es.search(\n        index= parametros.speed_index+'*',\n        body={\n                \"_source\": [\"beneficiary_code\",\"locationid\", \"result_start_date\"\n                            , \"result_download_mbps\", \"result_upload_mbps\"],\n                \"query\": {\n                    \"range\": {\n                        \"result_start_date\": {\n                            \"gte\": fecha_max_mintic.split(' ')[0]+'T00:00:00',\n                            \"lt\": fecha_tope_mintic.split(' ')[0]+'T23:59:59'\n                        }\n                    }\n                }\n\n        },\n        size=total_docs\n    )\n    #print(es.info())\n    elastic_docs = response[\"hits\"][\"hits\"]\n#     fields = {}\n#     for num, doc in enumerate(elastic_docs):\n#         source_data = doc[\"_source\"]\n#         for key, val in source_data.items():\n#             try:\n#                 fields[key] = np.append(fields[key], val)\n#             except KeyError:\n#                 fields[key] = np.array([val])\n\n    return pd.DataFrame([x[\"_source\"] for x in elastic_docs])\n\n\n# * Se genera fecha en yyyy-mm-dd, y cada campo por separado\n# * La hora y minuto se toma aparte\n# \n# Valores que se convierten a cero si son nulos\n# * trafico.anchoBandaDescarga\n# * trafico.anchoBandaCarga\n\n# In[782]:\n\n\nfecha_max_mintic = fecha_ejecucion\nfecha_tope_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)-timedelta(seconds=1)).strftime(\"%Y-%m-%d %H:%M:%S\")\ndatos_speed = traeVelocidad(fecha_max_mintic,fecha_tope_mintic)\n\nif datos_speed is None or datos_speed.empty:\n    while (datos_speed is None or datos_speed.empty) and ((datetime.strptime(fecha_max_mintic[0:10], '%Y-%m-%d').strftime(\"%Y-%m-%d %H:%M:%S\")) < str(now.strftime(\"%Y-%m-%d %H:%M:%S\"))):\n        fecha_max_mintic = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        fecha_tope_mintic = (datetime.strptime(fecha_tope_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)).strftime(\"%Y-%m-%d %H:%M:%S\")\n        datos_speed = traeVelocidad(fecha_max_mintic,fecha_tope_mintic)\nelse:\n    pass\n\n\n# In[783]:\n\n\ndatos_speed['beneficiary_code'] = datos_speed['beneficiary_code'].str.strip()\n\n\n# # 7. Speed test a indice\n\n# In[784]:\n\n\ntry:\n    datos_speed = datos_speed.drop(datos_speed[(datos_speed[\"result_download_mbps\"]<0) | (datos_speed[\"result_upload_mbps\"]<0)].index)\n    datos_speed['trafico.totales.fecha'] = datos_speed['result_start_date'].str.split(\"T\", n = 1, expand = True)[0]\n    datos_speed['result_download_mbps'] = datos_speed['result_download_mbps'] * 1000\n    datos_speed['result_upload_mbps'] = datos_speed['result_upload_mbps'] * 1000\n    datos_speed = datos_speed[['beneficiary_code','trafico.totales.fecha','result_download_mbps','result_upload_mbps']].groupby(['beneficiary_code','trafico.totales.fecha']).agg(['max']).reset_index()\n    datos_speed.columns = datos_speed.columns.droplevel(1)\n    datos_speed.rename(columns={'result_download_mbps': 'trafico.anchoBandaDescarga'\n                             ,'result_upload_mbps' :  'trafico.anchoBandaCarga'\n                             , 'beneficiary_code' : 'site_id'\n                             }, inplace=True)\n\n    datos_speed[\"trafico.totales.anyo\"] = datos_speed[\"trafico.totales.fecha\"].str[0:4]\n    datos_speed[\"trafico.totales.mes\"] = datos_speed[\"trafico.totales.fecha\"].str[5:7]\n    datos_speed[\"trafico.totales.dia\"] = datos_speed[\"trafico.totales.fecha\"].str[8:10]\n    datos_speed = pd.merge(datos_speed,  datos_semilla, on='site_id', how='inner')\n    datos_speed = datos_speed.rename(columns={'site_id' : 'trafico.siteID'})\n    datos_speed.dropna(subset=['trafico.anchoBandaDescarga','trafico.anchoBandaCarga'])\n    datos_speed.fillna({'trafico.anchoBandaDescarga':0\n                      , 'trafico.anchoBandaCarga':0\n                       },inplace=True)\n    datos_speed.fillna('', inplace=True)\n    datos_speed['nombreDepartamento'] = datos_speed['trafico.nombreDepartamento']\n    datos_speed['nombreMunicipio'] = datos_speed['trafico.nombreMunicipio']\n    datos_speed['idBeneficiario'] = datos_speed['trafico.idBeneficiario']\n    datos_speed['fecha'] = datos_speed['trafico.totales.fecha']\n    datos_speed['anyo'] = datos_speed['trafico.totales.anyo']\n    datos_speed['mes'] = datos_speed['trafico.totales.mes']\n    datos_speed['dia'] = datos_speed['trafico.totales.dia']\n    datos_speed['@timestamp'] = now.isoformat()\n        \n    #salida = helpers.bulk(es, doc_generator(datos_speed))\n    #print(\"Fecha: \", now,\"- Datos Velocidad carga y descarga (Trafico) en indice principal:\",salida[0])\nexcept Exception as e:\n    print(e)\n    #print(\"Fecha: \", now,\"- Ningun dato velocidad para insertar en indice principal\")\n\n\n# In[785]:\n\n\ntry:\n    use_these_keys = ['trafico.nomCentroDigital', \n                  'trafico.localidad',\n                  'trafico.siteID',\n                  'trafico.nombreDepartamento', \n                  'trafico.codISO', \n                  'trafico.sistemaEnergia',\n                  'trafico.nombreMunicipio', \n                  'trafico.idBeneficiario',\n                  'trafico.location', \n                  'trafico.anchoBandaDescarga',\n                  'trafico.anchoBandaCarga',\n                  'trafico.totales.fecha',\n                  'trafico.totales.anyo',\n                  'trafico.totales.mes',\n                  'trafico.totales.dia',\n                  'nombreDepartamento',\n                    'nombreMunicipio',\n                    'idBeneficiario',\n                    'fecha',\n                    'anyo',\n                    'mes',\n                    'dia',\n                  '@timestamp']\n\n    datos_speed['@timestamp'] = now.isoformat()\n    def doc_generator(df):\n        df_iter = df.iterrows()\n        for index, document in df_iter:\n            yield {\n                    \"_index\": indice, \n                    \"_id\": f\"{ 'Velocidad-' + document['trafico.siteID'] + '-' + document['trafico.totales.fecha']+ '-'+str(random.randrange(1000))}\",\n                    \"_source\": filterKeys(document),\n                }\n    salida = helpers.bulk(es, doc_generator(datos_speed))\n    print(\"Fecha: \", now,\"- Datos Velocidad carga y descarga (Trafico) en indice principal:\",salida[0])\nexcept Exception as e:\n    print(e)\n    print(\"Fecha: \", now,\"- Ningun dato velocidad para insertar en indice principal\")\n\n\n# ### Guardando fecha para control de ejecuciÃ³n\n\n# * Se actualiza la fecha de control. Si el calculo supera la fecha hora actual, se asocia esta ultima.\n\n# In[786]:\n\n\nfecha_ejecucion = (datetime.strptime(fecha_max_mintic, '%Y-%m-%d %H:%M:%S')+timedelta(minutes=120)).strftime(\"%Y-%m-%d %H:%M:%S\")[0:15] + '0:00'    \n\nif fecha_ejecucion > str(now.strftime('%Y-%m-%d %H:%M:%S'))[0:15] + '0:00':\n    fecha_ejecucion = str(now.strftime('%Y-%m-%d %H:%M:%S'))[0:15] + '0:00'\nresponse = es.index(\n        index = indice_control,\n        id = 'jerarquia_tablero_trafico',\n        body = { 'jerarquia_tablero_trafico': 'jerarquia_tablero_trafico','trafico.fechaControl' : fecha_ejecucion}\n)\nprint(\"actualizada fecha control de ejecucion:\",fecha_ejecucion)\n\n\n# In[ ]:\n\n\n\n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
